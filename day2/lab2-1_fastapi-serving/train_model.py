#!/usr/bin/env python3
"""
Lab 2-1: Iris ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
=============================

FastAPI ì„œë¹™ì„ ìœ„í•œ Iris ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

import sys
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
import numpy as np

def print_header():
    """í—¤ë” ì¶œë ¥"""
    print("=" * 60)
    print("  Lab 2-1: Iris ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    print()

def print_section(title):
    """ì„¹ì…˜ ì œëª© ì¶œë ¥"""
    print(f"\n{'â”€' * 60}")
    print(f"  {title}")
    print('â”€' * 60)

def load_and_prepare_data():
    """ë°ì´í„° ë¡œë“œ ë° ì¤€ë¹„"""
    print_section("Step 1: ë°ì´í„° ë¡œë“œ")
    
    print("  ğŸ”„ Iris ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    iris = load_iris()
    
    print(f"  âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"     - ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(iris.data)}")
    print(f"     - í”¼ì²˜ ìˆ˜: {len(iris.feature_names)}")
    print(f"     - í´ë˜ìŠ¤ ìˆ˜: {len(iris.target_names)}")
    print(f"     - í´ë˜ìŠ¤ ì´ë¦„: {', '.join(iris.target_names)}")
    
    print("\n  ğŸ“Š í”¼ì²˜ ì •ë³´:")
    for i, feature in enumerate(iris.feature_names, 1):
        print(f"     {i}. {feature}")
    
    # ë°ì´í„° ë¶„í• 
    print("\n  ğŸ”„ Train/Test ë°ì´í„° ë¶„í•  ì¤‘...")
    X_train, X_test, y_train, y_test = train_test_split(
        iris.data, iris.target, 
        test_size=0.2, 
        random_state=42,
        stratify=iris.target
    )
    
    print(f"  âœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ")
    print(f"     - í•™ìŠµ ë°ì´í„°: {len(X_train)} samples ({len(X_train)/len(iris.data)*100:.1f}%)")
    print(f"     - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)} samples ({len(X_test)/len(iris.data)*100:.1f}%)")
    
    # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
    print("\n  ğŸ“ˆ í´ë˜ìŠ¤ ë¶„í¬:")
    for i, class_name in enumerate(iris.target_names):
        train_count = np.sum(y_train == i)
        test_count = np.sum(y_test == i)
        print(f"     - {class_name}: Train={train_count}, Test={test_count}")
    
    return X_train, X_test, y_train, y_test, iris

def train_model(X_train, y_train):
    """ëª¨ë¸ í•™ìŠµ"""
    print_section("Step 2: ëª¨ë¸ í•™ìŠµ")
    
    print("  ğŸ”„ RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...")
    print("     - n_estimators: 100")
    print("     - random_state: 42")
    print("     - n_jobs: -1 (ëª¨ë“  CPU ì‚¬ìš©)")
    
    model = RandomForestClassifier(
        n_estimators=100, 
        random_state=42,
        n_jobs=-1,
        verbose=0
    )
    
    print("\n  â³ í•™ìŠµ ì§„í–‰ ì¤‘", end="", flush=True)
    for i in range(5):
        print(".", end="", flush=True)
        if i < 4:
            import time
            time.sleep(0.2)
    
    model.fit(X_train, y_train)
    print(" ì™„ë£Œ!")
    
    print(f"\n  âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
    print(f"     - íŠ¸ë¦¬ ê°œìˆ˜: {model.n_estimators}")
    print(f"     - í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°ë¨: {model.feature_importances_ is not None}")
    
    return model

def evaluate_model(model, X_train, X_test, y_train, y_test, iris):
    """ëª¨ë¸ í‰ê°€"""
    print_section("Step 3: ëª¨ë¸ í‰ê°€")
    
    print("  ğŸ”„ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ì¤‘...")
    
    # í•™ìŠµ ë°ì´í„° í‰ê°€
    train_predictions = model.predict(X_train)
    train_accuracy = accuracy_score(y_train, train_predictions)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
    test_predictions = model.predict(X_test)
    test_accuracy = accuracy_score(y_test, test_predictions)
    
    print(f"\n  ğŸ“Š ì •í™•ë„ (Accuracy):")
    print(f"     - í•™ìŠµ ë°ì´í„°: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)")
    print(f"     - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)")
    
    if train_accuracy - test_accuracy > 0.1:
        print(f"     âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„± (ì°¨ì´: {(train_accuracy-test_accuracy)*100:.2f}%)")
    else:
        print(f"     âœ… ì¼ë°˜í™” ì„±ëŠ¥ ì–‘í˜¸")
    
    # í”¼ì²˜ ì¤‘ìš”ë„
    print(f"\n  ğŸ¯ í”¼ì²˜ ì¤‘ìš”ë„:")
    feature_importance = sorted(
        zip(iris.feature_names, model.feature_importances_),
        key=lambda x: x[1],
        reverse=True
    )
    for i, (feature, importance) in enumerate(feature_importance, 1):
        bar = "â–ˆ" * int(importance * 50)
        print(f"     {i}. {feature:20s} {importance:.4f} {bar}")
    
    # í˜¼ë™ í–‰ë ¬
    print(f"\n  ğŸ“‹ í˜¼ë™ í–‰ë ¬ (Confusion Matrix):")
    cm = confusion_matrix(y_test, test_predictions)
    print("     " + "  ".join([f"{name:12s}" for name in iris.target_names]))
    for i, row in enumerate(cm):
        print(f"     {iris.target_names[i]:12s} ", end="")
        print("  ".join([f"{val:12d}" for val in row]))
    
    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
    print(f"\n  ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
    report = classification_report(
        y_test, test_predictions,
        target_names=iris.target_names,
        output_dict=True
    )
    for class_name in iris.target_names:
        metrics = report[class_name]
        print(f"     - {class_name:12s}: "
              f"Precision={metrics['precision']:.3f}, "
              f"Recall={metrics['recall']:.3f}, "
              f"F1-Score={metrics['f1-score']:.3f}")
    
    return test_accuracy

def save_model(model, filename="model.joblib"):
    """ëª¨ë¸ ì €ì¥"""
    print_section("Step 4: ëª¨ë¸ ì €ì¥")
    
    print(f"  ğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘: {filename}")
    joblib.dump(model, filename)
    
    # íŒŒì¼ í¬ê¸° í™•ì¸
    import os
    file_size = os.path.getsize(filename)
    if file_size < 1024:
        size_str = f"{file_size} bytes"
    elif file_size < 1024 * 1024:
        size_str = f"{file_size / 1024:.2f} KB"
    else:
        size_str = f"{file_size / (1024 * 1024):.2f} MB"
    
    print(f"  âœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ")
    print(f"     - íŒŒì¼ëª…: {filename}")
    print(f"     - íŒŒì¼ í¬ê¸°: {size_str}")
    print(f"     - ì €ì¥ ìœ„ì¹˜: {os.path.abspath(filename)}")

def print_next_steps():
    """ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´"""
    print("\n" + "=" * 60)
    print("  ğŸ‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)
    print("\n  ğŸ“ ë‹¤ìŒ ë‹¨ê³„:")
    print("     1. FastAPI ì„œë²„ ì‹¤í–‰:")
    print("        uvicorn app.main:app --reload --port 8000")
    print()
    print("     2. API í…ŒìŠ¤íŠ¸:")
    print("        curl http://localhost:8000/health")
    print()
    print("     3. Docker ë¹Œë“œ:")
    print("        docker build -t user<USER_NUM>:v1 .")
    print()
    print("     4. Kubernetes ë°°í¬:")
    print("        ./scripts/build_and_deploy.sh")
    print()
    print("  ğŸ’¡ ìì„¸í•œ ë‚´ìš©ì€ README.mdë¥¼ ì°¸ì¡°í•˜ì„¸ìš”.")
    print("=" * 60)
    print()

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    try:
        # í—¤ë” ì¶œë ¥
        print_header()
        
        # Step 1: ë°ì´í„° ë¡œë“œ
        X_train, X_test, y_train, y_test, iris = load_and_prepare_data()
        
        # Step 2: ëª¨ë¸ í•™ìŠµ
        model = train_model(X_train, y_train)
        
        # Step 3: ëª¨ë¸ í‰ê°€
        accuracy = evaluate_model(model, X_train, X_test, y_train, y_test, iris)
        
        # Step 4: ëª¨ë¸ ì €ì¥
        save_model(model)
        
        # ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        print_next_steps()
        
        return 0
        
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", file=sys.stderr)
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    sys.exit(main())
