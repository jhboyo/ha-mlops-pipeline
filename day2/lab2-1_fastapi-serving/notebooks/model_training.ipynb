{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2-1: FastAPI ëª¨ë¸ ì„œë¹™ - ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ ê°œìš”\n",
    "\n",
    "ì´ Notebookì—ì„œëŠ” Iris ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•˜ê³  í‰ê°€í•©ë‹ˆë‹¤.\n",
    "\n",
    "**í•™ìŠµ ë‚´ìš©:**\n",
    "1. ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰ (EDA)\n",
    "2. Train/Test ë°ì´í„° ë¶„í• \n",
    "3. RandomForest ëª¨ë¸ í•™ìŠµ\n",
    "4. ëª¨ë¸ í‰ê°€ ë° ì‹œê°í™”\n",
    "5. ëª¨ë¸ ì €ì¥\n",
    "6. ë¡œì»¬ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "**ì†Œìš”ì‹œê°„:** 30ë¶„\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  importí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš”í•œ ê²½ìš°)\n",
    "!pip install scikit-learn==1.5.2 numpy==1.26.4 pandas matplotlib seaborn joblib -q\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, \n",
    "    classification_report, \n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "# ì‹œê°í™” ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 1: ë°ì´í„° ë¡œë“œ ë° íƒìƒ‰\n",
    "\n",
    "Iris ë°ì´í„°ì…‹ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ\n",
    "print(\"=\" * 60)\n",
    "print(\"  Step 1: ë°ì´í„° ë¡œë“œ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"   - ì „ì²´ ìƒ˜í”Œ ìˆ˜: {len(X)}\")\n",
    "print(f\"   - í”¼ì²˜ ìˆ˜: {len(iris.feature_names)}\")\n",
    "print(f\"   - í´ë˜ìŠ¤ ìˆ˜: {len(iris.target_names)}\")\n",
    "print(f\"   - í´ë˜ìŠ¤ ì´ë¦„: {', '.join(iris.target_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "df = pd.DataFrame(X, columns=iris.feature_names)\n",
    "df['species'] = pd.Categorical.from_codes(y, iris.target_names)\n",
    "\n",
    "print(\"\\nğŸ“Š ë°ì´í„° ìƒ˜í”Œ (ì²˜ìŒ 5ê°œ):\")\n",
    "display(df.head())\n",
    "\n",
    "print(\"\\nğŸ“ˆ ê¸°ë³¸ í†µê³„:\")\n",
    "display(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í´ë˜ìŠ¤ ë¶„í¬\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ìƒ˜í”Œ ìˆ˜\n",
    "species_counts = df['species'].value_counts()\n",
    "axes[0].bar(species_counts.index, species_counts.values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Number of samples per class', fontsize=14, weight='bold')\n",
    "axes[0].set_xlabel('Species')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "axes[1].pie(species_counts.values, labels=species_counts.index, autopct='%1.1f%%',\n",
    "            colors=['#FF6B6B', '#4ECDC4', '#45B7D1'], startangle=90)\n",
    "axes[1].set_title('Class ratio', fontsize=14, weight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ… ê· í˜•ì¡íŒ ë°ì´í„°ì…‹: ê° í´ë˜ìŠ¤ë‹¹ 50ê°œ ìƒ˜í”Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”¼ì²˜ë³„ ë¶„í¬ (Pairplot)\n",
    "print(\"\\nğŸ” í”¼ì²˜ ê°„ ê´€ê³„ ì‹œê°í™”...\")\n",
    "sns.pairplot(df, hue='species', diag_kind='kde', plot_kws={'alpha': 0.6})\n",
    "plt.suptitle('Iris Features Pairplot', y=1.02, fontsize=16, weight='bold')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ ì¸ì‚¬ì´íŠ¸:\")\n",
    "print(\"   - petal lengthì™€ petal widthê°€ í´ë˜ìŠ¤ êµ¬ë¶„ì— ê°€ì¥ ìœ ìš©\")\n",
    "print(\"   - setosaëŠ” ë‹¤ë¥¸ í´ë˜ìŠ¤ì™€ ëª…í™•íˆ êµ¬ë¶„ë¨\")\n",
    "print(\"   - versicolorì™€ virginicaëŠ” ì•½ê°„ ê²¹ì¹¨\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 2: ë°ì´í„° ë¶„í• \n",
    "\n",
    "Train/Test ë°ì´í„°ë¡œ ë¶„í• í•©ë‹ˆë‹¤ (80:20 ë¹„ìœ¨)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  Step 2: ë°ì´í„° ë¶„í• \")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # í´ë˜ìŠ¤ ë¹„ìœ¨ ìœ ì§€\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„° ë¶„í•  ì™„ë£Œ\")\n",
    "print(f\"   - í•™ìŠµ ë°ì´í„°: {len(X_train)} samples ({len(X_train)/len(X)*100:.1f}%)\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)} samples ({len(X_test)/len(X)*100:.1f}%)\")\n",
    "\n",
    "# í´ë˜ìŠ¤ë³„ ë¶„í¬ í™•ì¸\n",
    "print(\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ë¶„í¬:\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    train_count = np.sum(y_train == i)\n",
    "    test_count = np.sum(y_test == i)\n",
    "    print(f\"   - {class_name:12s}: Train={train_count:2d}, Test={test_count:2d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 3: ëª¨ë¸ í•™ìŠµ\n",
    "\n",
    "RandomForest ë¶„ë¥˜ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  Step 3: ëª¨ë¸ í•™ìŠµ\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nğŸ”„ RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...\")\n",
    "print(\"   - n_estimators: 100\")\n",
    "print(\"   - random_state: 42\")\n",
    "print(\"   - n_jobs: -1 (ëª¨ë“  CPU ì‚¬ìš©)\")\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nâœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "print(f\"   - íŠ¸ë¦¬ ê°œìˆ˜: {model.n_estimators}\")\n",
    "print(f\"   - í”¼ì²˜ ê°œìˆ˜: {model.n_features_in_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 4: ëª¨ë¸ í‰ê°€\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  Step 4: ëª¨ë¸ í‰ê°€\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„° í‰ê°€\n",
    "train_predictions = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, train_predictions)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€\n",
    "test_predictions = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "print(f\"\\nğŸ“Š ì •í™•ë„ (Accuracy):\")\n",
    "print(f\"   - í•™ìŠµ ë°ì´í„°: {train_accuracy:.4f} ({train_accuracy*100:.2f}%)\")\n",
    "print(f\"   - í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "\n",
    "if train_accuracy - test_accuracy > 0.1:\n",
    "    print(f\"   âš ï¸  ê³¼ì í•© ê°€ëŠ¥ì„± (ì°¨ì´: {(train_accuracy-test_accuracy)*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"   âœ… ì¼ë°˜í™” ì„±ëŠ¥ ì–‘í˜¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”¼ì²˜ ì¤‘ìš”ë„ ê³„ì‚°\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': iris.feature_names,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nğŸ¯ í”¼ì²˜ ì¤‘ìš”ë„:\")\n",
    "for idx, row in feature_importance.iterrows():\n",
    "    bar = \"â–ˆ\" * int(row['importance'] * 50)\n",
    "    print(f\"   {row['feature']:25s} {row['importance']:.4f} {bar}\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['feature'], feature_importance['importance'], \n",
    "         color=['#FF6B6B', '#4ECDC4', '#45B7D1', '#95E1D3'])\n",
    "plt.xlabel('Importance', fontsize=12)\n",
    "plt.title('Feature Importance', fontsize=14, weight='bold')\n",
    "plt.grid(axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í˜¼ë™ í–‰ë ¬ (Confusion Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í˜¼ë™ í–‰ë ¬ ê³„ì‚°\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=iris.target_names,\n",
    "            yticklabels=iris.target_names,\n",
    "            cbar_kws={'label': 'Count'})\n",
    "plt.xlabel('Predicted', fontsize=12)\n",
    "plt.ylabel('Actual', fontsize=12)\n",
    "plt.title('Confusion Matrix', fontsize=14, weight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“‹ í˜¼ë™ í–‰ë ¬ (ìˆ«ì):\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í´ë˜ìŠ¤ë³„ ì„±ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "report = classification_report(\n",
    "    y_test, test_predictions,\n",
    "    target_names=iris.target_names,\n",
    "    output_dict=True\n",
    ")\n",
    "\n",
    "print(\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:\")\n",
    "for class_name in iris.target_names:\n",
    "    metrics = report[class_name]\n",
    "    print(f\"   - {class_name:12s}: \"\n",
    "          f\"Precision={metrics['precision']:.3f}, \"\n",
    "          f\"Recall={metrics['recall']:.3f}, \"\n",
    "          f\"F1-Score={metrics['f1-score']:.3f}\")\n",
    "\n",
    "# ì‹œê°í™”\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': [report[c]['precision'] for c in iris.target_names],\n",
    "    'Recall': [report[c]['recall'] for c in iris.target_names],\n",
    "    'F1-Score': [report[c]['f1-score'] for c in iris.target_names]\n",
    "}, index=iris.target_names)\n",
    "\n",
    "metrics_df.plot(kind='bar', figsize=(10, 6), rot=0, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "plt.title('Class-specific performance metrics', fontsize=14, weight='bold')\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.xlabel('Species', fontsize=12)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 5: ëª¨ë¸ ì €ì¥\n",
    "\n",
    "í•™ìŠµëœ ëª¨ë¸ì„ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"  Step 5: ëª¨ë¸ ì €ì¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "model_path = \"model.joblib\"\n",
    "print(f\"\\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì¤‘: {model_path}\")\n",
    "\n",
    "joblib.dump(model, model_path)\n",
    "\n",
    "# íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "file_size = os.path.getsize(model_path)\n",
    "if file_size < 1024:\n",
    "    size_str = f\"{file_size} bytes\"\n",
    "elif file_size < 1024 * 1024:\n",
    "    size_str = f\"{file_size / 1024:.2f} KB\"\n",
    "else:\n",
    "    size_str = f\"{file_size / (1024 * 1024):.2f} MB\"\n",
    "\n",
    "print(f\"\\nâœ… ëª¨ë¸ ì €ì¥ ì™„ë£Œ\")\n",
    "print(f\"   - íŒŒì¼ëª…: {model_path}\")\n",
    "print(f\"   - íŒŒì¼ í¬ê¸°: {size_str}\")\n",
    "print(f\"   - ì €ì¥ ìœ„ì¹˜: {os.path.abspath(model_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Step 6: ë¡œì»¬ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì €ì¥ëœ ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"  Step 6: ë¡œì»¬ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ëª¨ë¸ ë¡œë“œ\n",
    "print(f\"\\nğŸ“‚ ëª¨ë¸ ë¡œë“œ: {model_path}\")\n",
    "loaded_model = joblib.load(model_path)\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì„±ê³µ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: Setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setosa ìƒ˜í”Œ (ì „í˜•ì ì¸ ê°’)\n",
    "sample_setosa = np.array([[5.1, 3.5, 1.4, 0.2]])\n",
    "\n",
    "prediction = loaded_model.predict(sample_setosa)[0]\n",
    "probabilities = loaded_model.predict_proba(sample_setosa)[0]\n",
    "\n",
    "print(\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ 1: Setosa\")\n",
    "print(f\"   ì…ë ¥: {sample_setosa[0]}\")\n",
    "print(f\"   ì˜ˆì¸¡: {iris.target_names[prediction]}\")\n",
    "print(f\"   ì‹ ë¢°ë„: {probabilities[prediction]:.4f}\")\n",
    "print(f\"   í™•ë¥  ë¶„í¬:\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    print(f\"      - {class_name}: {probabilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: Versicolor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versicolor ìƒ˜í”Œ\n",
    "sample_versicolor = np.array([[5.9, 3.0, 4.2, 1.5]])\n",
    "\n",
    "prediction = loaded_model.predict(sample_versicolor)[0]\n",
    "probabilities = loaded_model.predict_proba(sample_versicolor)[0]\n",
    "\n",
    "print(\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ 2: Versicolor\")\n",
    "print(f\"   ì…ë ¥: {sample_versicolor[0]}\")\n",
    "print(f\"   ì˜ˆì¸¡: {iris.target_names[prediction]}\")\n",
    "print(f\"   ì‹ ë¢°ë„: {probabilities[prediction]:.4f}\")\n",
    "print(f\"   í™•ë¥  ë¶„í¬:\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    print(f\"      - {class_name}: {probabilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: Virginica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Virginica ìƒ˜í”Œ\n",
    "sample_virginica = np.array([[6.7, 3.0, 5.2, 2.3]])\n",
    "\n",
    "prediction = loaded_model.predict(sample_virginica)[0]\n",
    "probabilities = loaded_model.predict_proba(sample_virginica)[0]\n",
    "\n",
    "print(\"\\nğŸ§ª í…ŒìŠ¤íŠ¸ 3: Virginica\")\n",
    "print(f\"   ì…ë ¥: {sample_virginica[0]}\")\n",
    "print(f\"   ì˜ˆì¸¡: {iris.target_names[prediction]}\")\n",
    "print(f\"   ì‹ ë¢°ë„: {probabilities[prediction]:.4f}\")\n",
    "print(f\"   í™•ë¥  ë¶„í¬:\")\n",
    "for i, class_name in enumerate(iris.target_names):\n",
    "    print(f\"      - {class_name}: {probabilities[i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°°ì¹˜ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì—¬ëŸ¬ ìƒ˜í”Œ ë™ì‹œ ì˜ˆì¸¡\n",
    "samples = np.array([\n",
    "    [5.1, 3.5, 1.4, 0.2],  # Setosa\n",
    "    [5.9, 3.0, 4.2, 1.5],  # Versicolor\n",
    "    [6.7, 3.0, 5.2, 2.3]   # Virginica\n",
    "])\n",
    "\n",
    "predictions = loaded_model.predict(samples)\n",
    "probabilities = loaded_model.predict_proba(samples)\n",
    "\n",
    "print(\"\\nğŸ§ª ë°°ì¹˜ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸:\")\n",
    "for i, (sample, pred, probs) in enumerate(zip(samples, predictions, probabilities), 1):\n",
    "    print(f\"\\n   ìƒ˜í”Œ {i}:\")\n",
    "    print(f\"      ì…ë ¥: {sample}\")\n",
    "    print(f\"      ì˜ˆì¸¡: {iris.target_names[pred]}\")\n",
    "    print(f\"      ì‹ ë¢°ë„: {probs[pred]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ‰ ì™„ë£Œ!\n",
    "\n",
    "### âœ… ì™„ë£Œëœ ì‘ì—…\n",
    "\n",
    "- [x] ë°ì´í„° ë¡œë“œ ë° EDA\n",
    "- [x] Train/Test ë¶„í• \n",
    "- [x] RandomForest ëª¨ë¸ í•™ìŠµ\n",
    "- [x] ëª¨ë¸ í‰ê°€ ë° ì‹œê°í™”\n",
    "- [x] í”¼ì²˜ ì¤‘ìš”ë„ ë¶„ì„\n",
    "- [x] í˜¼ë™ í–‰ë ¬ í™•ì¸\n",
    "- [x] ëª¨ë¸ ì €ì¥ (`model.joblib`)\n",
    "- [x] ë¡œì»¬ ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "### ğŸ“ ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **FastAPI ì„œë²„ ì‹¤í–‰**\n",
    "   ```bash\n",
    "   # í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰\n",
    "   uvicorn app.main:app --reload --port 8000\n",
    "   ```\n",
    "\n",
    "2. **Docker ë¹Œë“œ ë° ë°°í¬**\n",
    "   ```bash\n",
    "   ./scripts/build_and_deploy.sh\n",
    "   ```\n",
    "\n",
    "3. **API í…ŒìŠ¤íŠ¸**\n",
    "   - `lab2-1_api_test.ipynb` Notebook ì‹¤í–‰\n",
    "   - ë˜ëŠ” `./scripts/test_api.sh` ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰\n",
    "\n",
    "### ğŸ“š ì°¸ê³  ìë£Œ\n",
    "\n",
    "- [Scikit-learn RandomForest ë¬¸ì„œ](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "- [Iris ë°ì´í„°ì…‹ ì„¤ëª…](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html)\n",
    "- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)\n",
    "\n",
    "---\n",
    "\n",
    "Â© 2025 í˜„ëŒ€ì˜¤í† ì—ë²„ MLOps Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
