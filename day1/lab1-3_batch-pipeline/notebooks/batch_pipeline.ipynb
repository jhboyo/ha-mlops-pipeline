{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸš€ Lab 1-3: Batch ë°ì´í„° íŒŒì´í”„ë¼ì¸\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ ê°œìš”\n",
    "\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ì†Œìš”ì‹œê°„** | 90ë¶„ (1.5ì‹œê°„) |\n",
    "| **ë‚œì´ë„** | â­â­â­ |\n",
    "| **ëª©í‘œ** | AWS S3 ê¸°ë°˜ Data Lake êµ¬ì¶• ë° Batch ë°ì´í„° ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸ êµ¬í˜„ |\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "ì´ ì‹¤ìŠµì„ í†µí•´ ë‹¤ìŒì„ í•™ìŠµí•©ë‹ˆë‹¤:\n",
    "- **AWS S3 ê¸°ë°˜ Data Lake ì•„í‚¤í…ì²˜** ì´í•´ ë° êµ¬ì¶•\n",
    "- **ETL Pipeline** ì„¤ê³„ ë° êµ¬í˜„\n",
    "- **ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬** ìë™í™”\n",
    "- **ëŒ€ê·œëª¨ Batch ë°ì´í„° ì²˜ë¦¬** (Pandas/AWS Wrangler í™œìš©)\n",
    "- **Bronze â†’ Silver â†’ Gold Layer** ë°ì´í„° íë¦„ ì´í•´\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ—ï¸ ì‹¤ìŠµ êµ¬ì¡°\n",
    "\n",
    "```\n",
    "Lab 1-3: Batch Data Pipeline (90ë¶„)\n",
    "â”œâ”€â”€ Part 1: ETL Pipeline (45ë¶„)\n",
    "â”‚   â”œâ”€â”€ S3 Data Lake êµ¬ì¶•\n",
    "â”‚   â”œâ”€â”€ ìƒ˜í”Œ ë°ì´í„° ìƒì„± (1000ëª… ê³ ê°)\n",
    "â”‚   â”œâ”€â”€ ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "â”‚   â””â”€â”€ ë°ì´í„° í’ˆì§ˆ ê²€ì¦\n",
    "â””â”€â”€ Part 2: Batch Processing (45ë¶„)\n",
    "    â”œâ”€â”€ Silver Layer ë°ì´í„° ì½ê¸°\n",
    "    â”œâ”€â”€ Batch ë°ì´í„° ì§‘ê³„ (Pandas)\n",
    "    â”œâ”€â”€ ê²°ê³¼ ë¶„ì„\n",
    "    â””â”€â”€ Gold Layer ì €ì¥\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âš ï¸ Cell 0: AWS ìê²© ì¦ëª… ì„¤ì • (í•„ìˆ˜!)\n",
    "\n",
    "**ì‹¤ìŠµ ì‹œì‘ ì „ ë°˜ë“œì‹œ AWS ìê²© ì¦ëª…ì„ ì„¤ì •í•˜ì„¸ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AWS ìê²© ì¦ëª… ì„¤ì • (í•„ìˆ˜!)\n",
    "# ============================================================\n",
    "import os\n",
    "\n",
    "# âš ï¸ ë³¸ì¸ì˜ ì‚¬ìš©ì ë²ˆí˜¸ë¡œ ë³€ê²½í•˜ì„¸ìš”!\n",
    "USER_NUM = \"01\"  # ì˜ˆ: \"01\", \"02\", \"03\"...\n",
    "\n",
    "# AWS ìê²© ì¦ëª… ì„¤ì • (ê°•ì‚¬ê°€ ì œê³µí•œ í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”!)\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'YOUR_ACCESS_KEY'          # ë³€ê²½ í•„ìš”!\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'YOUR_SECRET_KEY'      # ë³€ê²½ í•„ìš”!\n",
    "os.environ['AWS_DEFAULT_REGION'] = 'ap-northeast-2'\n",
    "os.environ['USER_NUM'] = USER_NUM\n",
    "\n",
    "print(f\"âœ… í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ!\")\n",
    "print(f\"   ì‚¬ìš©ì ë²ˆí˜¸: {USER_NUM}\")\n",
    "print(f\"   AWS ë¦¬ì „: ap-northeast-2 (ì„œìš¸)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AWS S3 ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "# ============================================================\n",
    "import boto3\n",
    "\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "try:\n",
    "    response = s3.list_buckets()\n",
    "    print(f\"âœ… AWS S3 ì—°ê²° ì„±ê³µ! ë²„í‚· ê°œìˆ˜: {len(response['Buckets'])}\")\n",
    "    print(\"\\nğŸ“¦ ê¸°ì¡´ ë²„í‚· ëª©ë¡:\")\n",
    "    for bucket in response['Buckets'][:5]:  # ìµœëŒ€ 5ê°œë§Œ í‘œì‹œ\n",
    "        print(f\"   - {bucket['Name']}\")\n",
    "    if len(response['Buckets']) > 5:\n",
    "        print(f\"   ... ì™¸ {len(response['Buckets']) - 5}ê°œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ AWS S3 ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nğŸ”§ í•´ê²° ë°©ë²•:\")\n",
    "    print(\"   1. AWS ìê²© ì¦ëª…ì„ ì˜¬ë°”ë¥´ê²Œ ì…ë ¥í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    print(\"   2. ê°•ì‚¬ì—ê²Œ ì•¡ì„¸ìŠ¤ í‚¤ë¥¼ ìš”ì²­í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ Part 1: ETL Pipeline (45ë¶„)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- S3 Data Lake êµ¬ì¡° ì´í•´ (Bronze/Silver/Gold ë ˆì´ì–´)\n",
    "- Extract-Transform-Load í”„ë¡œì„¸ìŠ¤ êµ¬í˜„\n",
    "- ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìë™í™”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-1: í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ë° í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„í¬íŠ¸\n",
    "# ============================================================\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from datetime import datetime, timedelta\n",
    "import awswrangler as wr\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„í¬íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"   pandas: {pd.__version__}\")\n",
    "print(f\"   numpy: {np.__version__}\")\n",
    "print(f\"   awswrangler: {wr.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# í™˜ê²½ ë³€ìˆ˜ ë° S3 ê²½ë¡œ ì„¤ì •\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"ETL íŒŒì´í”„ë¼ì¸ - í™˜ê²½ ì„¤ì •\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì½ê¸°\n",
    "USER_NUM = os.getenv('USER_NUM', '01')\n",
    "AWS_REGION = os.getenv('AWS_DEFAULT_REGION', 'ap-northeast-2')\n",
    "\n",
    "# S3 ë²„í‚· ì´ë¦„ ìƒì„± (ì‚¬ìš©ìë³„ ê³ ìœ )\n",
    "BUCKET_NAME = f\"mlops-training-user{USER_NUM}\"\n",
    "\n",
    "# Data Lake ë ˆì´ì–´ ì •ì˜\n",
    "BRONZE_LAYER = f\"s3://{BUCKET_NAME}/raw/\"          # ì›ë³¸ ë°ì´í„°\n",
    "SILVER_LAYER = f\"s3://{BUCKET_NAME}/processed/\"   # ì •ì œëœ ë°ì´í„°\n",
    "GOLD_LAYER = f\"s3://{BUCKET_NAME}/curated/\"       # ì§‘ê³„ëœ ë°ì´í„°\n",
    "\n",
    "print(f\"\\nğŸ“Œ ì„¤ì • ì •ë³´:\")\n",
    "print(f\"   ì‚¬ìš©ì: {USER_NUM}\")\n",
    "print(f\"   ë²„í‚·: {BUCKET_NAME}\")\n",
    "print(f\"   ë¦¬ì „: {AWS_REGION}\")\n",
    "print(f\"\\nğŸ“ Data Lake êµ¬ì¡°:\")\n",
    "print(f\"   Bronze Layer (ì›ë³¸): {BRONZE_LAYER}\")\n",
    "print(f\"   Silver Layer (ì •ì œ): {SILVER_LAYER}\")\n",
    "print(f\"   Gold Layer (ì§‘ê³„):   {GOLD_LAYER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-2: S3 Data Lake êµ¬ì¡° ìƒì„±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 1: S3 Data Lake êµ¬ì¡° ìƒì„±\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 1: S3 Data Lake ìƒì„±\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# boto3 S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "\n",
    "try:\n",
    "    # S3 ë²„í‚· ìƒì„±\n",
    "    s3_client.create_bucket(\n",
    "        Bucket=BUCKET_NAME,\n",
    "        CreateBucketConfiguration={'LocationConstraint': AWS_REGION}\n",
    "    )\n",
    "    print(f\"âœ… ë²„í‚· ìƒì„± ì™„ë£Œ: {BUCKET_NAME}\")\n",
    "except s3_client.exceptions.BucketAlreadyOwnedByYou:\n",
    "    print(f\"âœ… ë²„í‚·ì´ ì´ë¯¸ ì¡´ì¬í•¨: {BUCKET_NAME}\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  ë²„í‚· ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "    print(\"   (ë‹¤ë¥¸ ì‚¬ìš©ìê°€ ì´ë¯¸ ì‚¬ìš© ì¤‘ì¸ ë²„í‚· ì´ë¦„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
    "\n",
    "print(\"\\nğŸ“ Data Lake êµ¬ì¡°:\")\n",
    "print(f\"  Bronze Layer (ì›ë³¸): {BRONZE_LAYER}\")\n",
    "print(f\"  Silver Layer (ì •ì œ): {SILVER_LAYER}\")\n",
    "print(f\"  Gold Layer (ì§‘ê³„):   {GOLD_LAYER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-3: ìƒ˜í”Œ ê³ ê° ë°ì´í„° ìƒì„± (1000ëª…)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 2: ìƒ˜í”Œ ë°ì´í„° ìƒì„±\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 2: ìƒ˜í”Œ ë°ì´í„° ìƒì„±\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ ê°€ëŠ¥ì„±)\n",
    "np.random.seed(42)\n",
    "\n",
    "# ê³ ê° ë°ì´í„° ìƒì„±\n",
    "num_customers = 1000\n",
    "customer_ids = list(range(1, num_customers + 1))\n",
    "names = [f\"Customer_{i}\" for i in customer_ids]\n",
    "ages = np.random.randint(18, 70, num_customers)\n",
    "emails = [f\"user{i}@example.com\" for i in customer_ids]\n",
    "cities = np.random.choice(['Seoul', 'Busan', 'Incheon', 'Daegu'], num_customers)\n",
    "\n",
    "# ê°€ì…ì¼ ìƒì„± (ìµœê·¼ 1ë…„ ë‚´)\n",
    "join_dates = [\n",
    "    datetime.now() - timedelta(days=np.random.randint(1, 365))\n",
    "    for _ in range(num_customers)\n",
    "]\n",
    "\n",
    "print(f\"âœ… ê¸°ë³¸ ë°ì´í„° ìƒì„± ì™„ë£Œ: {num_customers}ëª…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# âš ï¸ ì˜ë„ì ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ì¶”ê°€ (10%)\n",
    "# ============================================================\n",
    "print(\"\\nâš ï¸ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ì¶”ê°€ (ETL ì‹¤ìŠµì„ ìœ„í•¨)...\")\n",
    "\n",
    "issue_indices = np.random.choice(num_customers, size=100, replace=False)\n",
    "\n",
    "# 1. Null ê°’ ì¶”ê°€ (33ê°œ)\n",
    "for idx in issue_indices[:33]:\n",
    "    emails[idx] = None\n",
    "\n",
    "# 2. ì¤‘ë³µ ì¶”ê°€ (33ê°œ)\n",
    "for idx in issue_indices[33:66]:\n",
    "    customer_ids[idx] = customer_ids[0]  # ì²« ë²ˆì§¸ IDì™€ ë™ì¼í•˜ê²Œ\n",
    "\n",
    "# 3. ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì¶”ê°€ (34ê°œ)\n",
    "for idx in issue_indices[66:]:\n",
    "    emails[idx] = f\"invalid_{idx}\"  # @ ì—†ëŠ” ì˜ëª»ëœ í˜•ì‹\n",
    "\n",
    "# DataFrame ìƒì„±\n",
    "df_customers = pd.DataFrame({\n",
    "    'customer_id': customer_ids,\n",
    "    'name': names,\n",
    "    'age': ages,\n",
    "    'email': emails,\n",
    "    'city': cities,\n",
    "    'join_date': join_dates\n",
    "})\n",
    "\n",
    "print(f\"\\nâœ… {len(df_customers)}ëª… ê³ ê° ë°ì´í„° ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"\\nğŸ“Š ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ (ì˜ë„ì ìœ¼ë¡œ ì¶”ê°€ë¨):\")\n",
    "print(f\"   - Null ê°’: {df_customers['email'].isnull().sum()}ê°œ\")\n",
    "print(f\"   - ì¤‘ë³µ ID: {df_customers['customer_id'].duplicated().sum()}ê°œ\")\n",
    "print(f\"   - ì˜ëª»ëœ í˜•ì‹: {len([e for e in emails if e and '@' not in str(e)])}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“‹ ìƒì„±ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "df_customers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ì •ë³´ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"ğŸ“Š ë°ì´í„° ì •ë³´:\")\n",
    "print(df_customers.info())\n",
    "print(\"\\nğŸ“ˆ í†µê³„ ìš”ì•½:\")\n",
    "df_customers.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-4: Bronze Layerì— ì›ë³¸ ë°ì´í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Bronze Layerì— ì €ì¥\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Bronze Layerì— ì›ë³¸ ë°ì´í„° ì €ì¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "bronze_path = BRONZE_LAYER + \"customers_raw/\"\n",
    "\n",
    "try:\n",
    "    wr.s3.to_parquet(\n",
    "        df=df_customers,\n",
    "        path=bronze_path,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… Bronze Layer ì €ì¥ ì™„ë£Œ: {bronze_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-5: ETL í”„ë¡œì„¸ìŠ¤ - Extract (ì¶”ì¶œ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# STEP 3: ETL í”„ë¡œì„¸ìŠ¤\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STEP 3: ETL ì²˜ë¦¬\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 3-1. Extract (ì¶”ì¶œ): Bronze Layerì—ì„œ ë°ì´í„° ì½ê¸°\n",
    "print(\"\\nğŸ“¥ Extract: Bronze Layerì—ì„œ ë°ì´í„° ì½ê¸°...\")\n",
    "df_raw = wr.s3.read_parquet(bronze_path)\n",
    "print(f\"âœ… Bronze Layerì—ì„œ {len(df_raw)}í–‰ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-6: ETL í”„ë¡œì„¸ìŠ¤ - Transform (ë³€í™˜)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-2. Transform (ë³€í™˜): ë°ì´í„° ê²€ì¦\n",
    "# ============================================================\n",
    "print(\"\\nğŸ” Transform: ë°ì´í„° ê²€ì¦ ì¤‘...\")\n",
    "\n",
    "# í’ˆì§ˆ ì´ìŠˆ ì¹´ìš´íŠ¸\n",
    "null_emails = df_raw['email'].isnull().sum()\n",
    "duplicate_ids = df_raw['customer_id'].duplicated().sum()\n",
    "invalid_emails = len(df_raw[df_raw['email'].notna() & ~df_raw['email'].str.contains('@', na=False)])\n",
    "\n",
    "print(f\"\\nâš ï¸ í’ˆì§ˆ ì´ìŠˆ ë°œê²¬:\")\n",
    "print(f\"   - Null ì´ë©”ì¼: {null_emails}ê°œ\")\n",
    "print(f\"   - ì¤‘ë³µ ID: {duplicate_ids}ê°œ\")\n",
    "print(f\"   - ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹: {invalid_emails}ê°œ\")\n",
    "print(f\"   - ì´ ì´ìŠˆ: {null_emails + duplicate_ids + invalid_emails}ê°œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-2. Transform (ë³€í™˜): ë°ì´í„° ì •ì œ\n",
    "# ============================================================\n",
    "print(\"\\nğŸ”§ Transform: ë°ì´í„° ì •ì œ ì¤‘...\")\n",
    "\n",
    "# ë°ì´í„° ì •ì œ\n",
    "df_clean = df_raw.copy()\n",
    "\n",
    "# 1) Null ì´ë©”ì¼ ì œê±°\n",
    "before_count = len(df_clean)\n",
    "df_clean = df_clean[df_clean['email'].notna()]\n",
    "print(f\"   âœ… Null ì´ë©”ì¼ ì œê±°: {before_count - len(df_clean)}í–‰\")\n",
    "\n",
    "# 2) ì¤‘ë³µ ì œê±° (customer_id ê¸°ì¤€)\n",
    "before_count = len(df_clean)\n",
    "df_clean = df_clean.drop_duplicates(subset=['customer_id'])\n",
    "print(f\"   âœ… ì¤‘ë³µ ì œê±°: {before_count - len(df_clean)}í–‰\")\n",
    "\n",
    "# 3) ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì œê±°\n",
    "before_count = len(df_clean)\n",
    "df_clean = df_clean[df_clean['email'].str.contains('@', na=False)]\n",
    "print(f\"   âœ… ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì œê±°: {before_count - len(df_clean)}í–‰\")\n",
    "\n",
    "print(f\"\\nâœ… ì •ì œëœ ë°ì´í„°: {len(df_clean)}í–‰\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-2. Transform (ë³€í™˜): ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“Š Transform: ë°ì´í„° ë³€í™˜ (ìƒˆ ì»¬ëŸ¼ ì¶”ê°€)...\")\n",
    "\n",
    "# 1) ì´ë©”ì¼ ë„ë©”ì¸ ì¶”ì¶œ\n",
    "df_clean['email_domain'] = df_clean['email'].str.split('@').str[1]\n",
    "print(f\"   âœ… email_domain ì»¬ëŸ¼ ì¶”ê°€\")\n",
    "\n",
    "# 2) ë‚˜ì´ëŒ€ ê·¸ë£¹ ìƒì„±\n",
    "def age_to_group(age):\n",
    "    \"\"\"ë‚˜ì´ë¥¼ ë‚˜ì´ëŒ€ ê·¸ë£¹ìœ¼ë¡œ ë³€í™˜\"\"\"\n",
    "    if age < 30:\n",
    "        return '20-29'\n",
    "    elif age < 40:\n",
    "        return '30-39'\n",
    "    elif age < 50:\n",
    "        return '40-49'\n",
    "    elif age < 60:\n",
    "        return '50-59'\n",
    "    else:\n",
    "        return '60+'\n",
    "\n",
    "df_clean['age_group'] = df_clean['age'].apply(age_to_group)\n",
    "print(f\"   âœ… age_group ì»¬ëŸ¼ ì¶”ê°€\")\n",
    "\n",
    "# ë³€í™˜ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "print(\"\\nğŸ“‹ ë³€í™˜ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-7: ETL í”„ë¡œì„¸ìŠ¤ - Load (ì ì¬)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3-3. Load (ì ì¬): Silver Layerì— ì €ì¥\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Load: Silver Layerì— ì •ì œëœ ë°ì´í„° ì €ì¥\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "silver_path = SILVER_LAYER + \"customers_cleaned/\"\n",
    "print(f\"\\nğŸ’¾ Silver Layerì— ì €ì¥ ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    wr.s3.to_parquet(\n",
    "        df=df_clean,\n",
    "        path=silver_path,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… ì €ì¥ ì™„ë£Œ: {silver_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-8: ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
    "total_rows = len(df_raw)\n",
    "cleaned_rows = len(df_clean)\n",
    "quality_score = (cleaned_rows / total_rows) * 100\n",
    "\n",
    "print(f\"\\nğŸ¯ ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%\")\n",
    "print(f\"\\nğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼:\")\n",
    "print(f\"   ì›ë³¸ ë°ì´í„°: {total_rows}í–‰\")\n",
    "print(f\"   ì •ì œëœ ë°ì´í„°: {cleaned_rows}í–‰\")\n",
    "print(f\"   ì œê±°ëœ ë°ì´í„°: {total_rows - cleaned_rows}í–‰\")\n",
    "\n",
    "# í’ˆì§ˆ ì´ìŠˆ ìš”ì•½\n",
    "print(f\"\\nâœ… í’ˆì§ˆ ì´ìŠˆ í•´ê²°:\")\n",
    "print(f\"   âœ… Null ê°’ ì²˜ë¦¬ ì™„ë£Œ\")\n",
    "print(f\"   âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ\")\n",
    "print(f\"   âœ… ë°ì´í„° í˜•ì‹ ê²€ì¦ ì™„ë£Œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… Part 1: ETL íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1-9: S3 ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# S3 ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“ S3 ì €ì¥ ê²°ê³¼ í™•ì¸:\")\n",
    "\n",
    "# Bronze Layer í™•ì¸\n",
    "bronze_files = wr.s3.list_objects(bronze_path)\n",
    "print(f\"\\nğŸ¥‰ Bronze Layer ({bronze_path}):\")\n",
    "for f in bronze_files[:3]:\n",
    "    print(f\"   - {f.split('/')[-1]}\")\n",
    "\n",
    "# Silver Layer í™•ì¸\n",
    "silver_files = wr.s3.list_objects(silver_path)\n",
    "print(f\"\\nğŸ¥ˆ Silver Layer ({silver_path}):\")\n",
    "for f in silver_files[:3]:\n",
    "    print(f\"   - {f.split('/')[-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ Part 2: Batch Processing (45ë¶„)\n",
    "\n",
    "## í•™ìŠµ ëª©í‘œ\n",
    "- ëŒ€ê·œëª¨ ë°ì´í„° Batch ì²˜ë¦¬\n",
    "- Pandas ë° AWS Wrangler í™œìš©\n",
    "- Gold Layer ë°ì´í„° ìƒì„±"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-1: Silver Layer ë°ì´í„° ì½ê¸°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Part 2: Batch Processing\n",
    "# ============================================================\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸš€ BATCH ë°ì´í„° ì²˜ë¦¬ (Pandas)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ“Œ ì„¤ì • ì •ë³´:\")\n",
    "print(f\"   ì‚¬ìš©ì: {USER_NUM}\")\n",
    "print(f\"   ë²„í‚·: {BUCKET_NAME}\")\n",
    "print(f\"   ë¦¬ì „: {AWS_REGION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Silver Layer ë°ì´í„° ì½ê¸°\n",
    "# ============================================================\n",
    "silver_path = f\"s3://{BUCKET_NAME}/processed/customers_cleaned/\"\n",
    "print(f\"\\n{'=' * 60}\")\n",
    "print(f\"ğŸ“¥ Silver Layer ë°ì´í„° ì½ê¸°\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"ê²½ë¡œ: {silver_path}\")\n",
    "\n",
    "try:\n",
    "    # AWS Wranglerë¡œ Parquet ì½ê¸°\n",
    "    df = wr.s3.read_parquet(silver_path)\n",
    "    print(f\"\\nâœ… {len(df)}í–‰ ë¡œë“œ ì™„ë£Œ\")\n",
    "    print(f\"\\nğŸ“Š ìŠ¤í‚¤ë§ˆ:\")\n",
    "    print(df.dtypes)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ë°ì´í„° ì½ê¸° ì‹¤íŒ¨: {e}\")\n",
    "    print(f\"\\nê°€ëŠ¥í•œ ì›ì¸:\")\n",
    "    print(f\"   1. Silver Layer ë°ì´í„°ê°€ ì—†ìŒ (Part 1ì„ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”)\")\n",
    "    print(f\"   2. S3 ê¶Œí•œ ë¬¸ì œ\")\n",
    "    print(f\"   3. ê²½ë¡œ ì˜¤ë¥˜\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Silver Layer ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“‹ Silver Layer ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-2: ë°ì´í„° ë¶„ì„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ë¶„ì„\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š ë°ì´í„° ë¶„ì„\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1ï¸âƒ£ ë„ì‹œë³„ ê³ ê° ìˆ˜ ì§‘ê³„\n",
    "# ============================================================\n",
    "print(\"\\n1ï¸âƒ£ ë„ì‹œë³„ ê³ ê° ìˆ˜:\")\n",
    "city_counts = df.groupby('city').size().reset_index(name='count')\n",
    "city_counts = city_counts.sort_values('count', ascending=False)\n",
    "print(city_counts.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2ï¸âƒ£ ë‚˜ì´ëŒ€ë³„ ë¶„í¬\n",
    "# ============================================================\n",
    "print(\"\\n2ï¸âƒ£ ë‚˜ì´ëŒ€ë³„ ë¶„í¬:\")\n",
    "age_group_counts = df.groupby('age_group').size().reset_index(name='count')\n",
    "age_group_counts = age_group_counts.sort_values('age_group')\n",
    "print(age_group_counts.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3ï¸âƒ£ ì´ë©”ì¼ ë„ë©”ì¸ë³„ ë¶„í¬ (Top 5)\n",
    "# ============================================================\n",
    "print(\"\\n3ï¸âƒ£ ì´ë©”ì¼ ë„ë©”ì¸ Top 5:\")\n",
    "domain_counts = df.groupby('email_domain').size().reset_index(name='count')\n",
    "domain_counts = domain_counts.sort_values('count', ascending=False).head(5)\n",
    "print(domain_counts.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4ï¸âƒ£ í†µê³„ ìš”ì•½\n",
    "# ============================================================\n",
    "print(\"\\n4ï¸âƒ£ í†µê³„ ìš”ì•½:\")\n",
    "stats = pd.DataFrame({\n",
    "    'avg_age': [df['age'].mean()],\n",
    "    'max_age': [df['age'].max()],\n",
    "    'min_age': [df['age'].min()],\n",
    "    'total_customers': [len(df)]\n",
    "})\n",
    "print(stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-3: ë°ì´í„° ì‹œê°í™” (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë°ì´í„° ì‹œê°í™” (ì„ íƒì‚¬í•­)\n",
    "# ============================================================\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "    \n",
    "    # ë„ì‹œë³„ ê³ ê° ìˆ˜ ì°¨íŠ¸\n",
    "    axes[0].bar(city_counts['city'], city_counts['count'], color='steelblue')\n",
    "    axes[0].set_title('Number of customers by city')\n",
    "    axes[0].set_xlabel('City')\n",
    "    axes[0].set_ylabel('Number of customers')\n",
    "    \n",
    "    # ë‚˜ì´ëŒ€ë³„ ë¶„í¬ ì°¨íŠ¸\n",
    "    axes[1].bar(age_group_counts['age_group'], age_group_counts['count'], color='coral')\n",
    "    axes[1].set_title('Distribution by age group')\n",
    "    axes[1].set_xlabel('Age group')\n",
    "    axes[1].set_ylabel('Number of customers')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    print(\"âœ… ì‹œê°í™” ì™„ë£Œ!\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"âš ï¸ matplotlibê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "    print(\"   ì„¤ì¹˜: pip install matplotlib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-4: Gold Layerì— ê²°ê³¼ ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Gold Layerì— ê²°ê³¼ ì €ì¥\n",
    "# ============================================================\n",
    "gold_path = f\"s3://{BUCKET_NAME}/curated/analysis/\"\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ’¾ Gold Layerì— ê²°ê³¼ ì €ì¥\")\n",
    "print(f\"{'=' * 60}\")\n",
    "print(f\"ê²½ë¡œ: {gold_path}\")\n",
    "\n",
    "try:\n",
    "    # 1) ë„ì‹œë³„ ë¶„ì„ ì €ì¥\n",
    "    city_output = gold_path + \"city_analysis/\"\n",
    "    wr.s3.to_parquet(\n",
    "        df=city_counts,\n",
    "        path=city_output,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"\\nâœ… ë„ì‹œë³„ ë¶„ì„ ì €ì¥: {city_output}\")\n",
    "    \n",
    "    # 2) ë‚˜ì´ëŒ€ë³„ ë¶„ì„ ì €ì¥\n",
    "    age_output = gold_path + \"age_analysis/\"\n",
    "    wr.s3.to_parquet(\n",
    "        df=age_group_counts,\n",
    "        path=age_output,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… ë‚˜ì´ëŒ€ë³„ ë¶„ì„ ì €ì¥: {age_output}\")\n",
    "    \n",
    "    # 3) ë„ë©”ì¸ë³„ ë¶„ì„ ì €ì¥\n",
    "    domain_output = gold_path + \"domain_analysis/\"\n",
    "    wr.s3.to_parquet(\n",
    "        df=domain_counts,\n",
    "        path=domain_output,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… ë„ë©”ì¸ë³„ ë¶„ì„ ì €ì¥: {domain_output}\")\n",
    "    \n",
    "    # 4) í†µê³„ ìš”ì•½ ì €ì¥\n",
    "    stats_output = gold_path + \"statistics/\"\n",
    "    wr.s3.to_parquet(\n",
    "        df=stats,\n",
    "        path=stats_output,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… í†µê³„ ìš”ì•½ ì €ì¥: {stats_output}\")\n",
    "    \n",
    "    # 5) ë©”íƒ€ë°ì´í„° ì €ì¥\n",
    "    metadata = pd.DataFrame({\n",
    "        'processed_at': [datetime.now()],\n",
    "        'total_rows': [len(df)],\n",
    "        'source': [silver_path]\n",
    "    })\n",
    "    metadata_output = gold_path + \"metadata/\"\n",
    "    wr.s3.to_parquet(\n",
    "        df=metadata,\n",
    "        path=metadata_output,\n",
    "        dataset=True,\n",
    "        mode='overwrite'\n",
    "    )\n",
    "    print(f\"âœ… ë©”íƒ€ë°ì´í„° ì €ì¥: {metadata_output}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì €ì¥ ì‹¤íŒ¨: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2-5: ìµœì¢… ê²°ê³¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ìµœì¢… ê²°ê³¼ í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… BATCH ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ“ ê²°ê³¼ ìœ„ì¹˜: {gold_path}\")\n",
    "print(f\"\\nğŸ” S3ì—ì„œ í™•ì¸:\")\n",
    "print(f\"   aws s3 ls s3://{BUCKET_NAME}/curated/analysis/ --recursive\")\n",
    "\n",
    "print(f\"\\nğŸ“Š ì²˜ë¦¬ëœ ë°ì´í„°:\")\n",
    "print(f\"   - ë„ì‹œë³„ ë¶„ì„: {len(city_counts)}ê°œ ë„ì‹œ\")\n",
    "print(f\"   - ë‚˜ì´ëŒ€ë³„ ë¶„ì„: {len(age_group_counts)}ê°œ ê·¸ë£¹\")\n",
    "print(f\"   - ë„ë©”ì¸ë³„ ë¶„ì„: Top {len(domain_counts)}\")\n",
    "print(f\"   - í†µê³„: í‰ê·  ë‚˜ì´ {stats['avg_age'].values[0]:.1f}ì„¸\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Gold Layer ê²°ê³¼ ê²€ì¦\n",
    "# ============================================================\n",
    "print(\"\\nğŸ“¥ Gold Layer ê²°ê³¼ ê²€ì¦:\")\n",
    "\n",
    "# ë„ì‹œë³„ ë¶„ì„ ì½ê¸°\n",
    "city_df = wr.s3.read_parquet(gold_path + \"city_analysis/\")\n",
    "print(f\"\\nğŸ™ï¸ ë„ì‹œë³„ ê³ ê° ìˆ˜:\")\n",
    "print(city_df)\n",
    "\n",
    "# ë‚˜ì´ëŒ€ë³„ ë¶„ì„ ì½ê¸°\n",
    "age_df = wr.s3.read_parquet(gold_path + \"age_analysis/\")\n",
    "print(f\"\\nğŸ‘¤ ë‚˜ì´ëŒ€ë³„ ë¶„í¬:\")\n",
    "print(age_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# âœ… ì‹¤ìŠµ ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "## Part 1: ETL Pipeline (45ë¶„)\n",
    "- [ ] S3 ë²„í‚· ìƒì„± ì™„ë£Œ\n",
    "- [ ] ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ (1000ëª…)\n",
    "- [ ] ETL íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì„±ê³µ\n",
    "- [ ] ë°ì´í„° í’ˆì§ˆ ì ìˆ˜ â‰¥ 90%\n",
    "- [ ] Silver Layer Parquet ì €ì¥ ì™„ë£Œ\n",
    "\n",
    "## Part 2: Batch Processing (45ë¶„)\n",
    "- [ ] Batch processing ìŠ¤í¬ë¦½íŠ¸ ì´í•´\n",
    "- [ ] Silver Layer ë°ì´í„° ë¡œë“œ ì„±ê³µ\n",
    "- [ ] ë„ì‹œë³„ ë¶„ì„ ê²°ê³¼ í™•ì¸\n",
    "- [ ] ë‚˜ì´ëŒ€ë³„ ë¶„ì„ ê²°ê³¼ í™•ì¸\n",
    "- [ ] Gold Layer ì €ì¥ ì™„ë£Œ\n",
    "- [ ] S3ì—ì„œ ê²°ê³¼ íŒŒì¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ì „ì²´ Data Lake êµ¬ì¡° í™•ì¸\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ† ì „ì²´ Data Lake êµ¬ì¡° í™•ì¸\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nğŸ¥‰ Bronze Layer (ì›ë³¸ ë°ì´í„°):\")\n",
    "try:\n",
    "    bronze_files = wr.s3.list_objects(BRONZE_LAYER)\n",
    "    print(f\"   íŒŒì¼ ìˆ˜: {len(bronze_files)}ê°œ\")\n",
    "except:\n",
    "    print(\"   (ë¹„ì–´ ìˆìŒ)\")\n",
    "\n",
    "print(f\"\\nğŸ¥ˆ Silver Layer (ì •ì œëœ ë°ì´í„°):\")\n",
    "try:\n",
    "    silver_files = wr.s3.list_objects(SILVER_LAYER)\n",
    "    print(f\"   íŒŒì¼ ìˆ˜: {len(silver_files)}ê°œ\")\n",
    "except:\n",
    "    print(\"   (ë¹„ì–´ ìˆìŒ)\")\n",
    "\n",
    "print(f\"\\nğŸ¥‡ Gold Layer (ì§‘ê³„ëœ ë°ì´í„°):\")\n",
    "try:\n",
    "    gold_files = wr.s3.list_objects(GOLD_LAYER)\n",
    "    print(f\"   íŒŒì¼ ìˆ˜: {len(gold_files)}ê°œ\")\n",
    "except:\n",
    "    print(\"   (ë¹„ì–´ ìˆìŒ)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ‰ Lab 1-3: Batch ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ğŸ¯ í•™ìŠµ ì„±ê³¼\n",
    "\n",
    "ì´ ì‹¤ìŠµì„ ì™„ë£Œí•˜ë©´:\n",
    "\n",
    "1. âœ… **Data Lake ì•„í‚¤í…ì²˜** ì´í•´ (Bronze/Silver/Gold Layer)\n",
    "2. âœ… **ETL Pipeline** ì™„ì „í•œ ì´í•´\n",
    "3. âœ… **ë°ì´í„° í’ˆì§ˆ ê´€ë¦¬** ìë™í™” êµ¬í˜„\n",
    "4. âœ… **Batch ë°ì´í„° ì²˜ë¦¬** ì‹¤ë¬´ ê²½í—˜\n",
    "5. âœ… **AWS Wrangler** í™œìš© ëŠ¥ë ¥\n",
    "6. âœ… **í”„ë¡œë•ì…˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸** ì„¤ê³„ ì—­ëŸ‰\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "**Day 2: ëª¨ë¸ ì„œë¹™ & ë²„ì „ ê´€ë¦¬**\n",
    "- Lab 2-1: FastAPI ëª¨ë¸ ì„œë¹™\n",
    "- Lab 2-2: MLflow Tracking & Registry\n",
    "- Lab 2-3: KServe ëª¨ë¸ ë°°í¬\n",
    "\n",
    "---\n",
    "\n",
    "Â© 2025 í˜„ëŒ€ì˜¤í† ì—ë²„ MLOps Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
