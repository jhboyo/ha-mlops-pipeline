#!/usr/bin/env python3
"""
Lab 1-3 Part 1: ETL Pipeline
AWS S3 ê¸°ë°˜ Data Lake êµ¬ì¶• ë° ë°ì´í„° ì •ì œ íŒŒì´í”„ë¼ì¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
1. S3 Data Lake êµ¬ì¡° ìƒì„± (Bronze/Silver/Gold Layer)
2. ìƒ˜í”Œ ê³ ê° ë°ì´í„° ìƒì„± (1000ëª…, ì˜ë„ì ì¸ í’ˆì§ˆ ì´ìŠˆ í¬í•¨)
3. ETL í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ (Extract-Transform-Load)
4. ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë° ì •ì œ
5. Silver Layerì— ì •ì œëœ ë°ì´í„° ì €ì¥
"""

import os
import pandas as pd
import numpy as np
import boto3
from datetime import datetime, timedelta
import awswrangler as wr

# ============================================================
# í™˜ê²½ ì„¤ì •
# ============================================================

print("=" * 60)
print("ETL íŒŒì´í”„ë¼ì¸")
print("=" * 60)

# í™˜ê²½ ë³€ìˆ˜ ì½ê¸°
USER_NUM = os.getenv('USER_NUM', '01')
AWS_ACCESS_KEY = os.getenv('AWS_ACCESS_KEY_ID')
AWS_SECRET_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')
AWS_REGION = os.getenv('AWS_DEFAULT_REGION', 'ap-northeast-2')

# S3 ë²„í‚· ì´ë¦„ ìƒì„±
BUCKET_NAME = f"mlops-training-user{USER_NUM}"

print(f"\nì‚¬ìš©ì: {USER_NUM}")
print(f"ë²„í‚·: {BUCKET_NAME}")
print(f"ë¦¬ì „: {AWS_REGION}")

# ============================================================
# STEP 1: S3 Data Lake êµ¬ì¡° ìƒì„±
# ============================================================

print("\n" + "=" * 60)
print("STEP 1: S3 Data Lake ìƒì„±")
print("=" * 60)

# boto3 S3 í´ë¼ì´ì–¸íŠ¸ ìƒì„±
s3_client = boto3.client('s3', region_name=AWS_REGION)

# Data Lake ë ˆì´ì–´ ì •ì˜
BRONZE_LAYER = f"s3://{BUCKET_NAME}/raw/"  # ì›ë³¸ ë°ì´í„°
SILVER_LAYER = f"s3://{BUCKET_NAME}/processed/"  # ì •ì œëœ ë°ì´í„°
GOLD_LAYER = f"s3://{BUCKET_NAME}/curated/"  # ì§‘ê³„ëœ ë°ì´í„°

print("\nData Lake êµ¬ì¡°:")
print(f"  Bronze Layer (ì›ë³¸): {BRONZE_LAYER}")
print(f"  Silver Layer (ì •ì œ): {SILVER_LAYER}")
print(f"  Gold Layer (ì§‘ê³„):   {GOLD_LAYER}")

# ============================================================
# STEP 2: ìƒ˜í”Œ ë°ì´í„° ìƒì„±
# ============================================================

print("\n" + "=" * 60)
print("STEP 2: ìƒ˜í”Œ ë°ì´í„° ìƒì„±")
print("=" * 60)

# ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ ê°€ëŠ¥ì„±)
np.random.seed(42)

# ê³ ê° ë°ì´í„° ìƒì„±
num_customers = 1000
customer_ids = list(range(1, num_customers + 1))
names = [f"Customer_{i}" for i in customer_ids]
ages = np.random.randint(18, 70, num_customers)
emails = [f"user{i}@example.com" for i in customer_ids]
cities = np.random.choice(['Seoul', 'Busan', 'Incheon', 'Daegu'], num_customers)

# ê°€ì…ì¼ ìƒì„± (ìµœê·¼ 1ë…„ ë‚´)
join_dates = [
    datetime.now() - timedelta(days=np.random.randint(1, 365))
    for _ in range(num_customers)
]

# âš ï¸ ì˜ë„ì ìœ¼ë¡œ ë°ì´í„° í’ˆì§ˆ ì´ìŠˆ ì¶”ê°€ (10%)
issue_indices = np.random.choice(num_customers, size=100, replace=False)

# 1. Null ê°’ ì¶”ê°€ (33ê°œ)
for idx in issue_indices[:33]:
    emails[idx] = None

# 2. ì¤‘ë³µ ì¶”ê°€ (33ê°œ)
for idx in issue_indices[33:66]:
    customer_ids[idx] = customer_ids[0]  # ì²« ë²ˆì§¸ IDì™€ ë™ì¼í•˜ê²Œ

# 3. ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì¶”ê°€ (34ê°œ)
for idx in issue_indices[66:]:
    emails[idx] = f"invalid_{idx}"  # @ ì—†ëŠ” ì˜ëª»ëœ í˜•ì‹

# DataFrame ìƒì„±
df_customers = pd.DataFrame({
    'customer_id': customer_ids,
    'name': names,
    'age': ages,
    'email': emails,
    'city': cities,
    'join_date': join_dates
})

print(f"âœ… {len(df_customers)}ëª… ê³ ê° ë°ì´í„° ìƒì„± ì™„ë£Œ")
print(f"\në°ì´í„° í’ˆì§ˆ ì´ìŠˆ (ì˜ë„ì ìœ¼ë¡œ ì¶”ê°€ë¨):")
print(f"  - Null ê°’: {df_customers['email'].isnull().sum()}ê°œ")
print(f"  - ì¤‘ë³µ: {df_customers['customer_id'].duplicated().sum()}ê°œ")
print(f"  - ì˜ëª»ëœ í˜•ì‹: {len([e for e in emails if e and '@' not in str(e)])}ê°œ")

# Bronze Layerì— ì €ì¥
bronze_path = BRONZE_LAYER + "customers_raw/"
wr.s3.to_parquet(
    df=df_customers,
    path=bronze_path,
    dataset=True,
    mode='overwrite'
)
print(f"\nâœ… Bronze Layer ì €ì¥ ì™„ë£Œ: {bronze_path}")

# ============================================================
# STEP 3: ETL í”„ë¡œì„¸ìŠ¤
# ============================================================

print("\n" + "=" * 60)
print("STEP 3: ETL ì²˜ë¦¬")
print("=" * 60)

# 3-1. Extract (ì¶”ì¶œ): Bronze Layerì—ì„œ ë°ì´í„° ì½ê¸°
df_raw = wr.s3.read_parquet(bronze_path)
print(f"ğŸ“¥ Bronze Layerì—ì„œ {len(df_raw)}í–‰ ë¡œë“œ")

# 3-2. Transform (ë³€í™˜): ë°ì´í„° ì •ì œ ë° ë³€í™˜

print("ğŸ” ë°ì´í„° ê²€ì¦ ì¤‘...")

# í’ˆì§ˆ ì´ìŠˆ ì¹´ìš´íŠ¸
null_emails = df_raw['email'].isnull().sum()
duplicate_ids = df_raw['customer_id'].duplicated().sum()
invalid_emails = len(df_raw[df_raw['email'].notna() & ~df_raw['email'].str.contains('@', na=False)])

print(f"\ní’ˆì§ˆ ì´ìŠˆ ë°œê²¬:")
print(f"  - Null ì´ë©”ì¼: {null_emails}ê°œ")
print(f"  - ì¤‘ë³µ ID: {duplicate_ids}ê°œ")
print(f"  - ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹: {invalid_emails}ê°œ")
print(f"  - ì´ ì´ìŠˆ: {null_emails + duplicate_ids + invalid_emails}ê°œ")

print(f"\nğŸ”§ ë°ì´í„° ì •ì œ ì¤‘:")

# ë°ì´í„° ì •ì œ
df_clean = df_raw.copy()

# 1) Null ì´ë©”ì¼ ì œê±°
before_count = len(df_clean)
df_clean = df_clean[df_clean['email'].notna()]
print(f"  âœ… Null ì´ë©”ì¼ ì œê±°: {before_count - len(df_clean)}í–‰")

# 2) ì¤‘ë³µ ì œê±° (customer_id ê¸°ì¤€)
before_count = len(df_clean)
df_clean = df_clean.drop_duplicates(subset=['customer_id'])
print(f"  âœ… ì¤‘ë³µ ì œê±°: {before_count - len(df_clean)}í–‰")

# 3) ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì œê±°
before_count = len(df_clean)
df_clean = df_clean[df_clean['email'].str.contains('@', na=False)]
print(f"  âœ… ì˜ëª»ëœ ì´ë©”ì¼ í˜•ì‹ ì œê±°: {before_count - len(df_clean)}í–‰")

print(f"  âœ… ì •ì œëœ ë°ì´í„°: {len(df_clean)}í–‰")

# ë°ì´í„° ë³€í™˜: ìƒˆë¡œìš´ ì»¬ëŸ¼ ì¶”ê°€
print(f"\nğŸ“Š ë°ì´í„° ë³€í™˜:")

# 1) ì´ë©”ì¼ ë„ë©”ì¸ ì¶”ì¶œ
df_clean['email_domain'] = df_clean['email'].str.split('@').str[1]
print(f"  âœ… email_domain ì»¬ëŸ¼ ì¶”ê°€")

# 2) ë‚˜ì´ëŒ€ ê·¸ë£¹ ìƒì„±
def age_to_group(age):
    """ë‚˜ì´ë¥¼ ë‚˜ì´ëŒ€ ê·¸ë£¹ìœ¼ë¡œ ë³€í™˜"""
    if age < 30:
        return '20-29'
    elif age < 40:
        return '30-39'
    elif age < 50:
        return '40-49'
    elif age < 60:
        return '50-59'
    else:
        return '60+'

df_clean['age_group'] = df_clean['age'].apply(age_to_group)
print(f"  âœ… age_group ì»¬ëŸ¼ ì¶”ê°€")

# 3-3. Load (ì ì¬): Silver Layerì— ì €ì¥
silver_path = SILVER_LAYER + "customers_cleaned/"
print(f"\nğŸ’¾ Silver Layerì— ì €ì¥ ì¤‘...")

wr.s3.to_parquet(
    df=df_clean,
    path=silver_path,
    dataset=True,
    mode='overwrite'
)
print(f"âœ… ì €ì¥ ì™„ë£Œ: {silver_path}")

# ============================================================
# ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸
# ============================================================

print("\n" + "=" * 60)
print("ë°ì´í„° í’ˆì§ˆ ë¦¬í¬íŠ¸")
print("=" * 60)

# í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
total_rows = len(df_raw)
cleaned_rows = len(df_clean)
quality_score = (cleaned_rows / total_rows) * 100

print(f"ë°ì´í„° í’ˆì§ˆ ì ìˆ˜: {quality_score:.1f}%")
print(f"\nì›ë³¸ ë°ì´í„°: {total_rows}í–‰")
print(f"ì •ì œëœ ë°ì´í„°: {cleaned_rows}í–‰")
print(f"ì œê±°ëœ ë°ì´í„°: {total_rows - cleaned_rows}í–‰")

# í’ˆì§ˆ ì´ìŠˆ ìš”ì•½
print(f"\ní’ˆì§ˆ ì´ìŠˆ í•´ê²°:")
print(f"  âœ… Null ê°’ ì²˜ë¦¬ ì™„ë£Œ")
print(f"  âœ… ì¤‘ë³µ ì œê±° ì™„ë£Œ")
print(f"  âœ… ë°ì´í„° í˜•ì‹ ê²€ì¦ ì™„ë£Œ")

print("\n" + "=" * 60)
print("âœ… ETL íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
print("=" * 60)

print(f"\në‹¤ìŒ ë‹¨ê³„:")
print(f"  - Silver Layer ë°ì´í„° í™•ì¸:")
print(f"    aws s3 ls {silver_path} --recursive")
print(f"\n  - Part 2 ì‹¤í–‰:")
print(f"    python scripts/2_batch_processing/pandas_batch_job.py")
