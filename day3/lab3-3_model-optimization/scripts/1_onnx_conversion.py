#!/usr/bin/env python3
"""
Lab 3-3 Part 1: ONNX Conversion
Scikit-learn ëª¨ë¸ì„ ONNX í¬ë§·ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

ì‹¤í–‰ ë°©ë²•:
    python scripts/1_onnx_conversion.py

ì¶œë ¥ íŒŒì¼:
    - outputs/model_original.joblib
    - outputs/model_optimized.onnx
"""

import os
import sys
import numpy as np
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„í¬íŠ¸
try:
    import joblib
    import onnx
    from onnx import helper
    import onnxruntime as ort
    from skl2onnx import convert_sklearn
    from skl2onnx.common.data_types import FloatTensorType
    from sklearn.datasets import load_iris
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score
except ImportError as e:
    print(f"âŒ í•„ìš”í•œ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {e}")
    print("   pip install -r requirements.txt ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
    sys.exit(1)


def print_header(title: str):
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 60)
    print(f"  {title}")
    print("=" * 60)


def print_step(step: int, description: str):
    """ë‹¨ê³„ ì¶œë ¥"""
    print(f"\nStep {step}: {description}")
    print("â”€" * 40)


def get_file_size(filepath: str) -> float:
    """íŒŒì¼ í¬ê¸°ë¥¼ KB ë‹¨ìœ„ë¡œ ë°˜í™˜"""
    return os.path.getsize(filepath) / 1024


def clean_onnx_opset(model):
    """
    ONNX ëª¨ë¸ì˜ opset_importë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤.
    ì¤‘ë³µëœ ë„ë©”ì¸ì„ ì œê±°í•˜ê³  ê¹¨ë—í•œ ìƒíƒœë¡œ ë§Œë“­ë‹ˆë‹¤.
    """
    # ê¸°ì¡´ opset ì •ë³´ ìˆ˜ì§‘ (ì¤‘ë³µ ì œê±°)
    opset_dict = {}
    for opset in model.opset_import:
        domain = opset.domain if opset.domain else ""
        # ê°™ì€ ë„ë©”ì¸ì´ ì´ë¯¸ ìˆìœ¼ë©´ ë” ë†’ì€ ë²„ì „ ìœ ì§€
        if domain not in opset_dict or opset.version > opset_dict[domain]:
            opset_dict[domain] = opset.version
    
    # ê¸°ì¡´ opset_import ëª¨ë‘ ì œê±°
    while len(model.opset_import) > 0:
        model.opset_import.pop()
    
    # ì •ë¦¬ëœ opset ë‹¤ì‹œ ì¶”ê°€
    for domain, version in opset_dict.items():
        opset = model.opset_import.add()
        opset.domain = domain
        opset.version = version
    
    return model


def main():
    print_header("Lab 3-3 Part 1: ONNX Conversion")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ì„¤ì •
    outputs_dir = PROJECT_ROOT / "outputs"
    outputs_dir.mkdir(parents=True, exist_ok=True)
    
    original_model_path = outputs_dir / "model_original.joblib"
    onnx_model_path = outputs_dir / "model_optimized.onnx"
    
    # =========================================================
    # Step 1: ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ
    # =========================================================
    print_step(1, "ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ")
    
    # Iris ë°ì´í„°ì…‹ ë¡œë“œ
    print("  ğŸ“Š Iris ë°ì´í„°ì…‹ ë¡œë“œ ì¤‘...")
    iris = load_iris()
    X, y = iris.data, iris.target
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    print(f"  ğŸ“Š í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}ê°œ")
    print(f"  ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ")
    print(f"  ğŸ“Š í”¼ì²˜ ìˆ˜: {X_train.shape[1]}")
    
    # RandomForest ëª¨ë¸ í•™ìŠµ
    print("  ğŸ‹ï¸ RandomForest ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=5,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # ì •í™•ë„ í™•ì¸
    train_accuracy = accuracy_score(y_train, model.predict(X_train))
    test_accuracy = accuracy_score(y_test, model.predict(X_test))
    print(f"  ğŸ“ˆ í•™ìŠµ ì •í™•ë„: {train_accuracy:.4f}")
    print(f"  ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}")
    
    # ì›ë³¸ ëª¨ë¸ ì €ì¥
    joblib.dump(model, original_model_path)
    print(f"  ğŸ’¾ ì›ë³¸ ëª¨ë¸ ì €ì¥: {original_model_path}")
    
    # =========================================================
    # Step 2: ONNX ë³€í™˜
    # =========================================================
    print_step(2, "ONNX ë³€í™˜")
    
    print("  ğŸ”„ Scikit-learn â†’ ONNX ë³€í™˜ ì¤‘...")
    
    # ì…ë ¥ íƒ€ì… ì •ì˜ (í”¼ì²˜ ìˆ˜ = 4)
    initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]
    
    # ONNX ë³€í™˜
    onnx_model = convert_sklearn(
        model, 
        initial_types=initial_type,
        target_opset=12,
        options={id(model): {'zipmap': False}}
    )
    
    # â­ í•µì‹¬: opset ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
    print("  ğŸ§¹ opset ì •ë¦¬ ì¤‘...")
    onnx_model = clean_onnx_opset(onnx_model)
    
    # ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬
    onnx.checker.check_model(onnx_model)
    print("  âœ… ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼")
    
    # ONNX ëª¨ë¸ ì €ì¥
    onnx.save(onnx_model, str(onnx_model_path))
    print(f"  ğŸ’¾ ONNX ëª¨ë¸ ì €ì¥: {onnx_model_path}")
    
    # =========================================================
    # Step 3: í¬ê¸° ë¹„êµ
    # =========================================================
    print_step(3, "ëª¨ë¸ í¬ê¸° ë¹„êµ")
    
    original_size = get_file_size(original_model_path)
    onnx_size = get_file_size(onnx_model_path)
    reduction = (1 - onnx_size / original_size) * 100
    
    print(f"  ğŸ“¦ ì›ë³¸ ëª¨ë¸ í¬ê¸°:  {original_size:.2f} KB")
    print(f"  ğŸ“¦ ONNX ëª¨ë¸ í¬ê¸°: {onnx_size:.2f} KB")
    print(f"  ğŸ“‰ í¬ê¸° ê°ì†Œìœ¨:    {reduction:.1f}%")
    
    # =========================================================
    # Step 4: ì˜ˆì¸¡ ê²€ì¦
    # =========================================================
    print_step(4, "ì˜ˆì¸¡ ê²€ì¦")
    
    print("  ğŸ”® ì›ë³¸ ëª¨ë¸ vs ONNX ëª¨ë¸ ì˜ˆì¸¡ ë¹„êµ...")
    
    # ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡
    original_pred = model.predict(X_test)
    
    # ONNX ëª¨ë¸ ì˜ˆì¸¡
    X_test_float32 = X_test.astype(np.float32)
    onnx_session = ort.InferenceSession(str(onnx_model_path))
    input_name = onnx_session.get_inputs()[0].name
    onnx_output = onnx_session.run(None, {input_name: X_test_float32})
    onnx_pred = onnx_output[0]
    
    # ì˜ˆì¸¡ ê²°ê³¼ê°€ ë ˆì´ë¸”ì´ ì•„ë‹Œ ê²½ìš° ì²˜ë¦¬
    if len(onnx_pred.shape) > 1 and onnx_pred.shape[1] > 1:
        onnx_pred = np.argmax(onnx_pred, axis=1)
    
    # ë¹„êµ
    predictions_match = np.sum(original_pred == onnx_pred)
    total_predictions = len(original_pred)
    match_rate = predictions_match / total_predictions * 100
    
    print(f"  ğŸ¯ ì˜ˆì¸¡ ì¼ì¹˜: {predictions_match}/{total_predictions} ({match_rate:.1f}%)")
    
    if match_rate == 100:
        print("  âœ… ëª¨ë“  ì˜ˆì¸¡ì´ ì¼ì¹˜í•©ë‹ˆë‹¤!")
    else:
        print(f"  âš ï¸ {total_predictions - predictions_match}ê°œì˜ ì˜ˆì¸¡ì´ ë‹¤ë¦…ë‹ˆë‹¤.")
    
    # ONNX ëª¨ë¸ ì •í™•ë„
    onnx_accuracy = accuracy_score(y_test, onnx_pred)
    print(f"  ğŸ“ˆ ONNX ëª¨ë¸ ì •í™•ë„: {onnx_accuracy:.4f}")
    
    # =========================================================
    # Step 5: ê²°ê³¼ ìš”ì•½
    # =========================================================
    print_step(5, "ê²°ê³¼ ìš”ì•½")
    
    print("""
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚                    ONNX ë³€í™˜ ê²°ê³¼ ìš”ì•½                   â”‚
  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤""")
    print(f"  â”‚  â€¢ ì›ë³¸ ëª¨ë¸:      {original_size:>8.2f} KB                       â”‚")
    print(f"  â”‚  â€¢ ONNX ëª¨ë¸:      {onnx_size:>8.2f} KB                       â”‚")
    print(f"  â”‚  â€¢ í¬ê¸° ê°ì†Œ:      {reduction:>8.1f}%                         â”‚")
    print(f"  â”‚  â€¢ ì˜ˆì¸¡ ì¼ì¹˜ìœ¨:    {match_rate:>8.1f}%                         â”‚")
    print("""  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """)
    
    print("  ğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"     - {original_model_path}")
    print(f"     - {onnx_model_path}")
    
    # opset ì •ë³´ ì¶œë ¥
    print("\n  ğŸ“‹ ONNX ëª¨ë¸ ì •ë³´ (ì •ë¦¬ë¨):")
    for opset in onnx_model.opset_import:
        domain = opset.domain if opset.domain else "ai.onnx"
        print(f"     - Domain: {domain}, Version: {opset.version}")
    
    print("\n" + "=" * 60)
    print("  âœ… Part 1 ì™„ë£Œ! ë‹¤ìŒ ë‹¨ê³„: python scripts/2_quantization.py")
    print("=" * 60 + "\n")


if __name__ == "__main__":
    main()
