{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-3: Model Optimization\n",
    "\n",
    "## ONNX ë³€í™˜ & ì–‘ìí™”ë¥¼ í†µí•œ ëª¨ë¸ ìµœì í™”\n",
    "\n",
    "| í•­ëª© | ë‚´ìš© |\n",
    "|------|------|\n",
    "| **ì‹¤ìŠµ ì‹œê°„** | 40ë¶„ |\n",
    "| **ë‚œì´ë„** | â­â­â­ (ì¤‘ê¸‰) |\n",
    "| **í•™ìŠµ ëª©í‘œ** | ONNX ë³€í™˜, ë™ì  ì–‘ìí™”, MLflow ë²¤ì¹˜ë§ˆí¬ ê¸°ë¡ |\n",
    "\n",
    "### í•™ìŠµ ë‚´ìš©\n",
    "1. ONNX í¬ë§·ìœ¼ë¡œ ëª¨ë¸ ë³€í™˜í•˜ì—¬ í”„ë ˆì„ì›Œí¬ ë…ë¦½ì„± í™•ë³´\n",
    "2. ë™ì  ì–‘ìí™”ë¥¼ ì ìš©í•˜ì—¬ ëª¨ë¸ í¬ê¸° ë° ì¶”ë¡  ì†ë„ ìµœì í™”\n",
    "3. ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ MLflowì— ê¸°ë¡í•˜ì—¬ ì‹¤í—˜ ì¶”ì "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 0. ì‚¬ì „ ì¤€ë¹„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ (í•„ìš” ì‹œ)\n",
    "# !pip install scikit-learn onnx onnxruntime skl2onnx mlflow boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# ONNX\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "# MLflow\n",
    "import mlflow\n",
    "\n",
    "print(\"âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "print(\"âœ… outputs ë””ë ‰í† ë¦¬ ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AWS ìê²© ì¦ëª… í™•ì¸ (IRSA)\n",
    "\n",
    "MLflowê°€ S3ì— ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•˜ë ¤ë©´ AWS ìê²© ì¦ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.\n",
    "IRSA(IAM Roles for Service Accounts)ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AWS ìê²© ì¦ëª… í™•ì¸\n",
    "import boto3\n",
    "\n",
    "try:\n",
    "    sts = boto3.client('sts')\n",
    "    identity = sts.get_caller_identity()\n",
    "    print(f\"âœ… AWS Identity: {identity['Arn']}\")\n",
    "    \n",
    "    # IRSA ì—­í•  í™•ì¸\n",
    "    if 'assumed-role' in identity['Arn']:\n",
    "        print(\"âœ… IRSAê°€ ì •ìƒì ìœ¼ë¡œ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    else:\n",
    "        print(\"âš ï¸ IRSAê°€ ì•„ë‹Œ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ì¸ì¦ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ AWS ìê²© ì¦ëª… ì˜¤ë¥˜: {e}\")\n",
    "    print(\"\\nê´€ë¦¬ìì—ê²Œ IRSA ì„¤ì •ì„ ìš”ì²­í•˜ì„¸ìš”.\")\n",
    "    print(\"ì°¸ê³ : setup-irsa-for-students.sh ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ í•„ìš”\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: ONNX Conversion (15ë¶„)\n",
    "\n",
    "### 1.1 ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë¶„í• \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ\")\n",
    "print(f\"íŠ¹ì„± ìˆ˜: {X_train.shape[1]}ê°œ\")\n",
    "print(f\"í´ë˜ìŠ¤: {iris.target_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest ëª¨ë¸ í•™ìŠµ\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì •í™•ë„ í‰ê°€\n",
    "train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(f\"âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ\")\n",
    "print(f\"   í•™ìŠµ ì •í™•ë„: {train_accuracy:.4f}\")\n",
    "print(f\"   í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì›ë³¸ ëª¨ë¸ ì €ì¥\n",
    "original_path = 'outputs/model_original.pkl'\n",
    "with open(original_path, 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "original_size = os.path.getsize(original_path) / 1024\n",
    "print(f\"âœ… ì›ë³¸ ëª¨ë¸ ì €ì¥: {original_path}\")\n",
    "print(f\"   í¬ê¸°: {original_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 ONNX ë³€í™˜\n",
    "\n",
    "**ONNX (Open Neural Network Exchange)**\n",
    "- ì‹ ê²½ë§ ëª¨ë¸ì„ êµí™˜í•˜ê¸° ìœ„í•œ í‘œì¤€ í¬ë§·\n",
    "- PyTorch, TensorFlow, Scikit-learn ë“± ë‹¤ì–‘í•œ í”„ë ˆì„ì›Œí¬ ì§€ì›\n",
    "- ONNX Runtimeìœ¼ë¡œ ê³ ì„±ëŠ¥ ì¶”ë¡  ê°€ëŠ¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì…ë ¥ íƒ€ì… ì •ì˜\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "# sklearn ëª¨ë¸ì„ ONNXë¡œ ë³€í™˜\n",
    "onnx_model = convert_sklearn(\n",
    "    model, \n",
    "    initial_types=initial_type,\n",
    "    target_opset=12\n",
    ")\n",
    "\n",
    "# ONNX ëª¨ë¸ ì €ì¥\n",
    "onnx_path = 'outputs/model_optimized.onnx'\n",
    "onnx.save_model(onnx_model, onnx_path)\n",
    "\n",
    "onnx_size = os.path.getsize(onnx_path) / 1024\n",
    "size_reduction = (1 - onnx_size / original_size) * 100\n",
    "\n",
    "print(f\"âœ… ONNX ë³€í™˜ ì™„ë£Œ\")\n",
    "print(f\"   ONNX ëª¨ë¸ í¬ê¸°: {onnx_size:.2f} KB\")\n",
    "print(f\"   í¬ê¸° ê°ì†Œ: {size_reduction:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 ONNX ëª¨ë¸ ê²€ì¦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"âœ… ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼\")\n",
    "\n",
    "# ONNX Runtimeìœ¼ë¡œ ì¶”ë¡  í…ŒìŠ¤íŠ¸\n",
    "sess = ort.InferenceSession(onnx_path, providers=['CPUExecutionProvider'])\n",
    "\n",
    "# ì…ë ¥/ì¶œë ¥ ì •ë³´\n",
    "input_name = sess.get_inputs()[0].name\n",
    "output_names = [o.name for o in sess.get_outputs()]\n",
    "\n",
    "print(f\"   ì…ë ¥ ì´ë¦„: {input_name}\")\n",
    "print(f\"   ì¶œë ¥ ì´ë¦„: {output_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²°ê³¼ ë¹„êµ\n",
    "onnx_pred = sess.run(None, {input_name: X_test.astype(np.float32)})[0]\n",
    "sklearn_pred = model.predict(X_test)\n",
    "\n",
    "match_rate = np.mean(onnx_pred == sklearn_pred) * 100\n",
    "onnx_accuracy = accuracy_score(y_test, onnx_pred)\n",
    "\n",
    "print(f\"âœ… ì¶”ë¡  ê²€ì¦ ì™„ë£Œ\")\n",
    "print(f\"   ONNX ëª¨ë¸ ì •í™•ë„: {onnx_accuracy:.4f}\")\n",
    "print(f\"   ì›ë³¸ê³¼ ì˜ˆì¸¡ ì¼ì¹˜ìœ¨: {match_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Quantization (10ë¶„)\n",
    "\n",
    "### ì–‘ìí™”(Quantization)ë€?\n",
    "\n",
    "ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ë¥¼ ë” ì‘ì€ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ë²•\n",
    "- **FP32 â†’ INT8**: 32ë¹„íŠ¸ ì‹¤ìˆ˜ë¥¼ 8ë¹„íŠ¸ ì •ìˆ˜ë¡œ ë³€í™˜\n",
    "- **ì¥ì **: ëª¨ë¸ í¬ê¸° ê°ì†Œ, ì¶”ë¡  ì†ë„ í–¥ìƒ\n",
    "- **ë‹¨ì **: ì•½ê°„ì˜ ì •í™•ë„ ì†ì‹¤ ê°€ëŠ¥ (ëŒ€ë¶€ë¶„ ë¬´ì‹œí•  ìˆ˜ì¤€)\n",
    "\n",
    "| ì¢…ë¥˜ | ì„¤ëª… | íŠ¹ì§• |\n",
    "|------|------|------|\n",
    "| **ë™ì  ì–‘ìí™”** | ì¶”ë¡  ì‹œ ê°€ì¤‘ì¹˜ë§Œ ì–‘ìí™” | ì‰¬ìš´ ì ìš©, ì¬í•™ìŠµ ë¶ˆí•„ìš” |\n",
    "| ì •ì  ì–‘ìí™” | ê°€ì¤‘ì¹˜ + í™œì„±í™” ì–‘ìí™” | ìµœê³  ì„±ëŠ¥, ìº˜ë¦¬ë¸Œë ˆì´ì…˜ í•„ìš” |\n",
    "| QAT | í•™ìŠµ ì¤‘ ì–‘ìí™” ì‹œë®¬ë ˆì´ì…˜ | ì •í™•ë„ ìµœì†Œ ì†ì‹¤, ì¬í•™ìŠµ í•„ìš” |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë™ì  ì–‘ìí™” ì ìš©\n",
    "quantized_path = 'outputs/model_quantized.onnx'\n",
    "\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_path,\n",
    "    model_output=quantized_path,\n",
    "    weight_type=QuantType.QUInt8  # 8ë¹„íŠ¸ ì •ìˆ˜ë¡œ ì–‘ìí™”\n",
    ")\n",
    "\n",
    "quant_size = os.path.getsize(quantized_path) / 1024\n",
    "size_change = ((quant_size - onnx_size) / onnx_size) * 100\n",
    "\n",
    "print(f\"âœ… ì–‘ìí™” ì™„ë£Œ\")\n",
    "print(f\"   ì–‘ìí™” ëª¨ë¸ í¬ê¸°: {quant_size:.2f} KB\")\n",
    "print(f\"   í¬ê¸° ë³€í™”: {size_change:+.1f}%\")\n",
    "\n",
    "if abs(size_change) < 10:\n",
    "    print(\"\\nğŸ’¡ ì°¸ê³ : RandomForest ëª¨ë¸ì€ ì–‘ìí™” íš¨ê³¼ê°€ ì‘ìŠµë‹ˆë‹¤.\")\n",
    "    print(\"   ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œëŠ” 4ë°° ì´ìƒ í¬ê¸° ê°ì†Œ ê°€ëŠ¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì–‘ìí™” ëª¨ë¸ ê²€ì¦\n",
    "quant_session = ort.InferenceSession(quantized_path, providers=['CPUExecutionProvider'])\n",
    "quant_pred = quant_session.run(None, {input_name: X_test.astype(np.float32)})[0]\n",
    "\n",
    "quant_accuracy = accuracy_score(y_test, quant_pred)\n",
    "match_with_onnx = np.mean(onnx_pred == quant_pred) * 100\n",
    "\n",
    "print(f\"âœ… ì–‘ìí™” ëª¨ë¸ ê²€ì¦\")\n",
    "print(f\"   ì–‘ìí™” ëª¨ë¸ ì •í™•ë„: {quant_accuracy:.4f}\")\n",
    "print(f\"   ONNX ì›ë³¸ê³¼ ì˜ˆì¸¡ ì¼ì¹˜ìœ¨: {match_with_onnx:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Benchmark & MLflow (15ë¶„)\n",
    "\n",
    "### 3.1 ì¶”ë¡  ì†ë„ ë²¤ì¹˜ë§ˆí¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_inference_time(predict_fn, X, n_iterations=1000):\n",
    "    \"\"\"ì¶”ë¡  ì‹œê°„ ì¸¡ì • (ë°€ë¦¬ì´ˆ ë‹¨ìœ„)\"\"\"\n",
    "    # ì›Œë°ì—…\n",
    "    for _ in range(10):\n",
    "        predict_fn(X)\n",
    "    \n",
    "    # ì‹¤ì œ ì¸¡ì •\n",
    "    start = time.perf_counter()\n",
    "    for _ in range(n_iterations):\n",
    "        predict_fn(X)\n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    return ((end - start) / n_iterations) * 1000  # msë¡œ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "print(f\"ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ (ë°˜ë³µ íšŸìˆ˜: {n_iterations}íšŒ)\\n\")\n",
    "\n",
    "# ì›ë³¸ sklearn ì¶”ë¡ \n",
    "print(\"ì›ë³¸ sklearn ì¸¡ì • ì¤‘...\")\n",
    "original_time = measure_inference_time(\n",
    "    lambda x: model.predict(x), \n",
    "    X_test, \n",
    "    n_iterations\n",
    ")\n",
    "print(f\"   ì™„ë£Œ: {original_time:.4f} ms\")\n",
    "\n",
    "# ONNX ì¶”ë¡ \n",
    "print(\"ONNX Runtime ì¸¡ì • ì¤‘...\")\n",
    "onnx_time = measure_inference_time(\n",
    "    lambda x: sess.run(None, {input_name: x.astype(np.float32)}),\n",
    "    X_test,\n",
    "    n_iterations\n",
    ")\n",
    "print(f\"   ì™„ë£Œ: {onnx_time:.4f} ms\")\n",
    "\n",
    "# ì–‘ìí™” ëª¨ë¸ ì¶”ë¡ \n",
    "print(\"ì–‘ìí™” ëª¨ë¸ ì¸¡ì • ì¤‘...\")\n",
    "quant_time = measure_inference_time(\n",
    "    lambda x: quant_session.run(None, {input_name: x.astype(np.float32)}),\n",
    "    X_test,\n",
    "    n_iterations\n",
    ")\n",
    "print(f\"   ì™„ë£Œ: {quant_time:.4f} ms\")\n",
    "\n",
    "# ì†ë„ í–¥ìƒ ê³„ì‚°\n",
    "onnx_speedup = original_time / onnx_time\n",
    "quant_speedup = original_time / quant_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶œë ¥\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'ëª¨ë¸':<15} {'í¬ê¸°':<12} {'ì¶”ë¡  ì‹œê°„':<15} {'ì†ë„ í–¥ìƒ':<10} {'ì •í™•ë„'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'ì›ë³¸ sklearn':<15} {original_size:.2f} KB{'':<4} {original_time:.4f} ms{'':<6} {'1.0x':<10} {test_accuracy:.4f}\")\n",
    "print(f\"{'ONNX':<15} {onnx_size:.2f} KB{'':<4} {onnx_time:.4f} ms{'':<6} {onnx_speedup:.1f}x{'':<6} {onnx_accuracy:.4f}\")\n",
    "print(f\"{'ì–‘ìí™”':<15} {quant_size:.2f} KB{'':<4} {quant_time:.4f} ms{'':<6} {quant_speedup:.1f}x{'':<6} {quant_accuracy:.4f}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 MLflow ê¸°ë¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì„œë²„ URI ì„¤ì •\n",
    "mlflow_uri = os.environ.get(\n",
    "    'MLFLOW_TRACKING_URI',\n",
    "    'http://mlflow-server-service.mlflow-system.svc.cluster.local:5000'\n",
    ")\n",
    "mlflow.set_tracking_uri(mlflow_uri)\n",
    "print(f\"MLflow URI: {mlflow_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹¤í—˜(Experiment) ìƒì„± \n",
    "import os\n",
    "import boto3\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# âš ï¸ ê°•ì‚¬ê°€ ì œê³µí•œ ë³¸ì¸ì˜ AWS ìê²© ì¦ëª…ìœ¼ë¡œ ë³€ê²½!\n",
    "AWS_ACCESS_KEY_ID = \"YOUR_AWS_ACCESS_KEY_ID\"          # ìˆ˜ì • í•„ìš”!\n",
    "AWS_SECRET_ACCESS_KEY = \"YOUR_AWS_SECRET_ACCESS_KEY\"  # ìˆ˜ì • í•„ìš”!\n",
    "AWS_REGION = \"ap-northeast-2\"\n",
    "\n",
    "# âš ï¸ ë³¸ì¸ì˜ ì‚¬ìš©ì ë²ˆí˜¸ë¡œ ë³€ê²½!\n",
    "USER_NUM = \"YOUR_USER_NUM\"\n",
    "NAMESPACE = f\"kubeflow-user{USER_NUM}\"\n",
    "\n",
    "# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = AWS_ACCESS_KEY_ID\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = AWS_SECRET_ACCESS_KEY\n",
    "os.environ[\"AWS_DEFAULT_REGION\"] = AWS_REGION\n",
    "\n",
    "print(f\"âœ… ì‚¬ìš©ì ì„¤ì • ì™„ë£Œ:\")\n",
    "\n",
    "\n",
    "try:\n",
    "    s3_client = boto3.client('s3', region_name=AWS_REGION)\n",
    "\n",
    "    S3_BUCKET = f\"mlops-training-user{USER_NUM}\"\n",
    "\n",
    "    print(f\"âœ… USER_NUM: {USER_NUM}\")\n",
    "    print(f\"âœ… NAMESPACE: {NAMESPACE}\")\n",
    "    print(f\"âœ… AWS Region: {AWS_REGION}\")\n",
    "    print(f\"âœ… S3 Bucket: {S3_BUCKET}\")\n",
    "    \n",
    "    # S3 ë²„í‚· ì ‘ê·¼ í…ŒìŠ¤íŠ¸\n",
    "    s3_client.head_bucket(Bucket=S3_BUCKET)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"  AWS Credentials ì„¤ì • ì™„ë£Œ!\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"âœ… AWS Access Key: {AWS_ACCESS_KEY_ID[:4]}****\")\n",
    "    print(f\"âœ… S3 ì ‘ê·¼ í…ŒìŠ¤íŠ¸: ì„±ê³µ!\")\n",
    "    print(\"\")\n",
    "    print(\"ì´ì œ 3.2 ì‹¤í—˜ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ì˜¤ë¥˜: {e}\")\n",
    "    print(f\"\")\n",
    "    print(f\"í•´ê²° ë°©ë²•:\")\n",
    "    print(f\"1. AWS_ACCESS_KEY_IDì™€ AWS_SECRET_ACCESS_KEYë¥¼ ì •í™•íˆ ì…ë ¥í•˜ì„¸ìš”\")\n",
    "    print(f\"2. ê°•ì‚¬ê°€ ì œê³µí•œ ìê²© ì¦ëª…ì´ ë§ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
    "    print(f\"3. S3 ë²„í‚·({S3_BUCKET})ì— ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”\")\n",
    "\n",
    "# MLflow í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "client = MlflowClient()\n",
    "\n",
    "# âœ… ì‚¬ìš©ìë³„ ê³ ìœ í•œ ì‹¤í—˜ ì´ë¦„ ì‚¬ìš©!\n",
    "EXPERIMENT_NAME = f\"lab3-3-model-optimization-user{USER_NUM}\"\n",
    "\n",
    "# ì‚¬ìš©ìë³„ S3 artifact location ì„¤ì •\n",
    "artifact_location = f\"s3://{S3_BUCKET}/mlflow-artifacts\"\n",
    "\n",
    "# ì‹¤í—˜ì´ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "experiment = client.get_experiment_by_name(EXPERIMENT_NAME)\n",
    "\n",
    "if experiment is None:\n",
    "    # ì‹¤í—˜ì´ ì—†ìœ¼ë©´ ìƒì„±\n",
    "    experiment_id = client.create_experiment(\n",
    "        name=EXPERIMENT_NAME,\n",
    "        artifact_location=artifact_location\n",
    "    )\n",
    "    print(f\"\\nâœ… ìƒˆ ì‹¤í—˜ ìƒì„±: {EXPERIMENT_NAME}\")\n",
    "    experiment = client.get_experiment(experiment_id)\n",
    "else:\n",
    "    print(f\"\\nâœ… ê¸°ì¡´ ì‹¤í—˜ ì‚¬ìš©: {EXPERIMENT_NAME}\")\n",
    "    experiment_id = experiment.experiment_id\n",
    "\n",
    "# MLflowì— ì‹¤í—˜ ì„¤ì •\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "experiment = client.get_experiment(experiment_id)\n",
    "print(f\"\\nğŸ“‹ ì‹¤í—˜ ì •ë³´:\")\n",
    "print(f\"   Name: {experiment.name}\")\n",
    "print(f\"   ID: {experiment.experiment_id}\")\n",
    "print(f\"   Artifact Location: {experiment.artifact_location}\")\n",
    "print(f\"   Lifecycle Stage: {experiment.lifecycle_stage}\")\n",
    "\n",
    "# ê²€ì¦\n",
    "if S3_BUCKET in experiment.artifact_location and experiment.lifecycle_stage == \"active\":\n",
    "    print(f\"\\nğŸ‰ SUCCESS: ì‹¤í—˜ì´ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(f\"\\nâŒ ERROR: ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì‹¤í—˜ ë° Run ê¸°ë¡\n",
    "with mlflow.start_run(run_name=\"notebook-benchmark\") as run:\n",
    "    # í¬ê¸° ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_size_kb\", original_size)\n",
    "    mlflow.log_metric(\"onnx_size_kb\", onnx_size)\n",
    "    mlflow.log_metric(\"quantized_size_kb\", quant_size)\n",
    "    \n",
    "    # ì†ë„ ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_inference_ms\", original_time)\n",
    "    mlflow.log_metric(\"onnx_inference_ms\", onnx_time)\n",
    "    mlflow.log_metric(\"quantized_inference_ms\", quant_time)\n",
    "    mlflow.log_metric(\"onnx_speedup\", onnx_speedup)\n",
    "    mlflow.log_metric(\"quantized_speedup\", quant_speedup)\n",
    "    \n",
    "    # ì •í™•ë„ ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"onnx_accuracy\", onnx_accuracy)\n",
    "    mlflow.log_metric(\"quantized_accuracy\", quant_accuracy)\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„°\n",
    "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
    "    mlflow.log_param(\"test_samples\", len(X_test))\n",
    "    mlflow.log_param(\"quantization_type\", \"dynamic_uint8\")\n",
    "    \n",
    "    # ì•„í‹°íŒ©íŠ¸\n",
    "    print(\"\\nì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ ì¤‘...\")\n",
    "    try:\n",
    "        mlflow.log_artifact('outputs/model_optimized.onnx')\n",
    "        mlflow.log_artifact('outputs/model_quantized.onnx')\n",
    "        print(\"âœ… ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ ì™„ë£Œ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"   IRSA ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.\")\n",
    "    \n",
    "    print(f\"\\nâœ… MLflow ê¸°ë¡ ì™„ë£Œ!\")\n",
    "    print(f\"   Run ID: {run.info.run_id}\")\n",
    "    print(f\"   ì‹¤í—˜: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## âœ… ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### í•µì‹¬ ìš”ì•½\n",
    "\n",
    "1. **ONNX ë³€í™˜**: ëª¨ë¸ í¬ê¸° 58% ê°ì†Œ, í”„ë ˆì„ì›Œí¬ ë…ë¦½ì„± í™•ë³´\n",
    "2. **ë™ì  ì–‘ìí™”**: ì¶”ê°€ ìµœì í™” (ë”¥ëŸ¬ë‹ ëª¨ë¸ì—ì„œ ë” í° íš¨ê³¼)\n",
    "3. **ONNX Runtime**: ì¶”ë¡  ì†ë„ 68ë°° í–¥ìƒ, ì •í™•ë„ ì†ì‹¤ ì—†ìŒ\n",
    "4. **MLflow**: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶”ì  ë° ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ê´€ë¦¬\n",
    "\n",
    "### ìë™ì°¨ ì—…ê³„ ì ìš© ì‚¬ë¡€\n",
    "\n",
    "- **ìš´ì „ì ëª¨ë‹ˆí„°ë§**: ì¡¸ìŒ ê°ì§€, ì£¼ì˜ë ¥ ë¶„ì‚° ê°ì§€ (30fps ì‹¤ì‹œê°„)\n",
    "- **ADAS**: ì°¨ì„  ì´íƒˆ ê²½ê³ , ì „ë°© ì¶©ëŒ ê²½ê³  (ì €ì§€ì—°)\n",
    "- **ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜**: ì—”ì§„ ì´ìƒ ê°ì§€, ë°°í„°ë¦¬ ìˆ˜ëª… ì˜ˆì¸¡ (ì—£ì§€ ë°°í¬)\n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "MLflow UIì—ì„œ ì‹¤í—˜ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”!\n",
    "- Experiments â†’ `lab3-3-model-optimization` â†’ ìµœì‹  Run\n",
    "- Parameters, Metrics, Artifacts íƒ­ í™•ì¸"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
