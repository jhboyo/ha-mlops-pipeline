{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-3: Model Optimization (ONNX & Quantization)\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì—ì„œëŠ” **ëª¨ë¸ ìµœì í™”**ë¥¼ ëŒ€í™”í˜•ìœ¼ë¡œ ì‹¤ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ ë‚´ìš©\n",
    "\n",
    "1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "2. Scikit-learn ëª¨ë¸ í•™ìŠµ\n",
    "3. ONNX ë³€í™˜\n",
    "4. ë™ì  ì–‘ìí™” ì ìš©\n",
    "5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
    "6. MLflow ë©”íŠ¸ë¦­ ê¸°ë¡\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •\n",
    "\n",
    "í•„ìš”í•œ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê³  importí•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install scikit-learn onnx onnxruntime skl2onnx mlflow joblib numpy -q\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import joblib\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Import ì™„ë£Œ\")\n",
    "print(f\"ONNX Runtime ë²„ì „: {ort.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ë°ì´í„° ë¡œë“œ ë° ëª¨ë¸ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iris ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"ğŸ“Š í•™ìŠµ ë°ì´í„°: {X_train.shape[0]}ê°œ\")\n",
    "print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: {X_test.shape[0]}ê°œ\")\n",
    "print(f\"ğŸ“Š í”¼ì²˜ ìˆ˜: {X_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest ëª¨ë¸ í•™ìŠµ\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    random_state=42\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ì •í™•ë„ í™•ì¸\n",
    "train_accuracy = accuracy_score(y_train, model.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "print(f\"ğŸ“ˆ í•™ìŠµ ì •í™•ë„: {train_accuracy:.4f}\")\n",
    "print(f\"ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì •í™•ë„: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ì €ì¥\n",
    "joblib.dump(model, 'outputs/model_original.joblib')\n",
    "original_size = os.path.getsize('outputs/model_original.joblib') / 1024\n",
    "\n",
    "print(f\"ğŸ’¾ ì›ë³¸ ëª¨ë¸ ì €ì¥: outputs/model_original.joblib\")\n",
    "print(f\"ğŸ“¦ ëª¨ë¸ í¬ê¸°: {original_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. ONNX ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_onnx_opset(model):\n",
    "    \"\"\"ONNX ëª¨ë¸ì˜ opset ì¤‘ë³µ ì œê±°\"\"\"\n",
    "    opset_dict = {}\n",
    "    for opset in model.opset_import:\n",
    "        domain = opset.domain if opset.domain else \"\"\n",
    "        if domain not in opset_dict or opset.version > opset_dict[domain]:\n",
    "            opset_dict[domain] = opset.version\n",
    "    \n",
    "    while len(model.opset_import) > 0:\n",
    "        model.opset_import.pop()\n",
    "    \n",
    "    for domain, version in opset_dict.items():\n",
    "        opset = model.opset_import.add()\n",
    "        opset.domain = domain\n",
    "        opset.version = version\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX ë³€í™˜\n",
    "print(\"ğŸ”„ Scikit-learn â†’ ONNX ë³€í™˜ ì¤‘...\")\n",
    "\n",
    "initial_type = [('float_input', FloatTensorType([None, X_train.shape[1]]))]\n",
    "\n",
    "onnx_model = convert_sklearn(\n",
    "    model, \n",
    "    initial_types=initial_type,\n",
    "    target_opset=12,\n",
    "    options={id(model): {'zipmap': False}}\n",
    ")\n",
    "\n",
    "# opset ì •ë¦¬\n",
    "onnx_model = clean_onnx_opset(onnx_model)\n",
    "\n",
    "# ìœ íš¨ì„± ê²€ì‚¬\n",
    "onnx.checker.check_model(onnx_model)\n",
    "print(\"âœ… ONNX ëª¨ë¸ ìœ íš¨ì„± ê²€ì‚¬ í†µê³¼\")\n",
    "\n",
    "# ì €ì¥\n",
    "onnx.save(onnx_model, 'outputs/model_optimized.onnx')\n",
    "onnx_size = os.path.getsize('outputs/model_optimized.onnx') / 1024\n",
    "\n",
    "print(f\"ğŸ’¾ ONNX ëª¨ë¸ ì €ì¥: outputs/model_optimized.onnx\")\n",
    "print(f\"ğŸ“¦ ONNX ëª¨ë¸ í¬ê¸°: {onnx_size:.2f} KB\")\n",
    "print(f\"ğŸ“‰ í¬ê¸° ê°ì†Œ: {(1 - onnx_size/original_size)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONNX ëª¨ë¸ ì •ë³´ í™•ì¸\n",
    "print(\"ğŸ“‹ ONNX ëª¨ë¸ opset ì •ë³´:\")\n",
    "for opset in onnx_model.opset_import:\n",
    "    domain = opset.domain if opset.domain else \"ai.onnx\"\n",
    "    print(f\"   - Domain: {domain}, Version: {opset.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì˜ˆì¸¡ ê²€ì¦\n",
    "X_test_float32 = X_test.astype(np.float32)\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸ ì˜ˆì¸¡\n",
    "original_pred = model.predict(X_test)\n",
    "\n",
    "# ONNX ëª¨ë¸ ì˜ˆì¸¡\n",
    "onnx_session = ort.InferenceSession('outputs/model_optimized.onnx')\n",
    "input_name = onnx_session.get_inputs()[0].name\n",
    "onnx_output = onnx_session.run(None, {input_name: X_test_float32})\n",
    "onnx_pred = onnx_output[0]\n",
    "\n",
    "if len(onnx_pred.shape) > 1 and onnx_pred.shape[1] > 1:\n",
    "    onnx_pred = np.argmax(onnx_pred, axis=1)\n",
    "\n",
    "# ë¹„êµ\n",
    "match_rate = np.sum(original_pred == onnx_pred) / len(original_pred) * 100\n",
    "print(f\"ğŸ¯ ì˜ˆì¸¡ ì¼ì¹˜ìœ¨: {match_rate:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ì–‘ìí™” (Quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.ERROR)\n",
    "\n",
    "print(\"ğŸ”„ ë™ì  ì–‘ìí™” ì ìš© ì¤‘...\")\n",
    "\n",
    "try:\n",
    "    quantize_dynamic(\n",
    "        model_input='outputs/model_optimized.onnx',\n",
    "        model_output='outputs/model_quantized.onnx',\n",
    "        weight_type=QuantType.QUInt8,\n",
    "    )\n",
    "    print(\"âœ… ì–‘ìí™” ì™„ë£Œ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ QUInt8 ì‹¤íŒ¨, QInt8ë¡œ ì¬ì‹œë„: {e}\")\n",
    "    quantize_dynamic(\n",
    "        model_input='outputs/model_optimized.onnx',\n",
    "        model_output='outputs/model_quantized.onnx',\n",
    "        weight_type=QuantType.QInt8,\n",
    "    )\n",
    "    print(\"âœ… ì–‘ìí™” ì™„ë£Œ (QInt8)\")\n",
    "\n",
    "quant_size = os.path.getsize('outputs/model_quantized.onnx') / 1024\n",
    "print(f\"ğŸ“¦ ì–‘ìí™” ëª¨ë¸ í¬ê¸°: {quant_size:.2f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì–‘ìí™” ëª¨ë¸ ì •í™•ë„ ê²€ì¦\n",
    "quant_session = ort.InferenceSession('outputs/model_quantized.onnx')\n",
    "quant_input_name = quant_session.get_inputs()[0].name\n",
    "quant_output = quant_session.run(None, {quant_input_name: X_test_float32})\n",
    "quant_pred = quant_output[0]\n",
    "\n",
    "if len(quant_pred.shape) > 1 and quant_pred.shape[1] > 1:\n",
    "    quant_pred = np.argmax(quant_pred, axis=1)\n",
    "\n",
    "quant_accuracy = accuracy_score(y_test, quant_pred)\n",
    "print(f\"ğŸ“ˆ ì–‘ìí™” ëª¨ë¸ ì •í™•ë„: {quant_accuracy:.4f} ({quant_accuracy*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_inference(predict_fn, X_test, n_iterations=1000):\n",
    "    \"\"\"ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\"\"\"\n",
    "    # ì›Œë°ì—…\n",
    "    for _ in range(10):\n",
    "        predict_fn(X_test)\n",
    "    \n",
    "    # ë²¤ì¹˜ë§ˆí¬\n",
    "    times = []\n",
    "    for _ in range(n_iterations):\n",
    "        start = time.perf_counter()\n",
    "        predict_fn(X_test)\n",
    "        end = time.perf_counter()\n",
    "        times.append((end - start) * 1000)\n",
    "    \n",
    "    return np.mean(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iterations = 1000\n",
    "print(f\"â±ï¸ ê° ëª¨ë¸ {n_iterations}íšŒ ì¶”ë¡  ìˆ˜í–‰ ì¤‘...\")\n",
    "\n",
    "# ì›ë³¸ ëª¨ë¸\n",
    "original_time = benchmark_inference(\n",
    "    lambda x: model.predict(x), X_test, n_iterations\n",
    ")\n",
    "\n",
    "# ONNX ëª¨ë¸\n",
    "onnx_time = benchmark_inference(\n",
    "    lambda x: onnx_session.run(None, {input_name: x.astype(np.float32)})[0],\n",
    "    X_test, n_iterations\n",
    ")\n",
    "\n",
    "# ì–‘ìí™” ëª¨ë¸\n",
    "quant_time = benchmark_inference(\n",
    "    lambda x: quant_session.run(None, {quant_input_name: x.astype(np.float32)})[0],\n",
    "    X_test, n_iterations\n",
    ")\n",
    "\n",
    "# ì†ë„ í–¥ìƒ ê³„ì‚°\n",
    "onnx_speedup = original_time / onnx_time\n",
    "quant_speedup = original_time / quant_time\n",
    "\n",
    "print(f\"\\nâ±ï¸ ì¶”ë¡  ì‹œê°„ (í‰ê· ):\")\n",
    "print(f\"   â€¢ ì›ë³¸ sklearn: {original_time:.4f} ms (1.0x)\")\n",
    "print(f\"   â€¢ ONNX:         {onnx_time:.4f} ms ({onnx_speedup:.1f}x)\")\n",
    "print(f\"   â€¢ ì–‘ìí™”:       {quant_time:.4f} ms ({quant_speedup:.1f}x)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*65)\n",
    "print(\"                     ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½\")\n",
    "print(\"=\"*65)\n",
    "print(f\"{'ëª¨ë¸':<15} | {'í¬ê¸° (KB)':>10} | {'ì¶”ë¡  (ms)':>10} | {'ì†ë„í–¥ìƒ':>8} | {'ì •í™•ë„':>8}\")\n",
    "print(\"-\"*65)\n",
    "print(f\"{'ì›ë³¸ sklearn':<15} | {original_size:>10.2f} | {original_time:>10.4f} | {'1.0x':>8} | {test_accuracy*100:>7.2f}%\")\n",
    "print(f\"{'ONNX':<15} | {onnx_size:>10.2f} | {onnx_time:>10.4f} | {onnx_speedup:>7.1f}x | {accuracy_score(y_test, onnx_pred)*100:>7.2f}%\")\n",
    "print(f\"{'ì–‘ìí™”':<15} | {quant_size:>10.2f} | {quant_time:>10.4f} | {quant_speedup:>7.1f}x | {quant_accuracy*100:>7.2f}%\")\n",
    "print(\"=\"*65)\n",
    "\n",
    "print(\"\\nğŸ¯ í•µì‹¬ ì„±ê³¼:\")\n",
    "print(f\"   â€¢ ëª¨ë¸ í¬ê¸°: {original_size:.1f} KB â†’ {quant_size:.1f} KB ({(1-quant_size/original_size)*100:.1f}% ê°ì†Œ)\")\n",
    "print(f\"   â€¢ ì¶”ë¡  ì†ë„: {original_time:.2f} ms â†’ {quant_time:.2f} ms ({quant_speedup:.1f}x í–¥ìƒ)\")\n",
    "print(f\"   â€¢ ì •í™•ë„ ìœ ì§€: {quant_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. MLflow ê¸°ë¡ (ì„ íƒ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow Tracking URI ì„¤ì •\n",
    "import mlflow\n",
    "\n",
    "MLFLOW_URI = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\"\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "print(f\"ğŸ”— MLflow Tracking URI: {MLFLOW_URI}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLflow ì‹¤í—˜ ë° Run ê¸°ë¡\n",
    "experiment_name = \"lab3-3-model-optimization\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "with mlflow.start_run(run_name=\"notebook-benchmark\"):\n",
    "    # í¬ê¸° ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_size_kb\", original_size)\n",
    "    mlflow.log_metric(\"onnx_size_kb\", onnx_size)\n",
    "    mlflow.log_metric(\"quantized_size_kb\", quant_size)\n",
    "    \n",
    "    # ì†ë„ ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_inference_ms\", original_time)\n",
    "    mlflow.log_metric(\"onnx_inference_ms\", onnx_time)\n",
    "    mlflow.log_metric(\"quantized_inference_ms\", quant_time)\n",
    "    mlflow.log_metric(\"onnx_speedup\", onnx_speedup)\n",
    "    mlflow.log_metric(\"quantized_speedup\", quant_speedup)\n",
    "    \n",
    "    # ì •í™•ë„ ë©”íŠ¸ë¦­\n",
    "    mlflow.log_metric(\"original_accuracy\", test_accuracy)\n",
    "    mlflow.log_metric(\"quantized_accuracy\", quant_accuracy)\n",
    "    \n",
    "    # íŒŒë¼ë¯¸í„°\n",
    "    mlflow.log_param(\"n_iterations\", n_iterations)\n",
    "    mlflow.log_param(\"quantization_type\", \"dynamic_uint8\")\n",
    "    \n",
    "    # ì•„í‹°íŒ©íŠ¸\n",
    "    mlflow.log_artifact('outputs/model_optimized.onnx')\n",
    "    mlflow.log_artifact('outputs/model_quantized.onnx')\n",
    "    \n",
    "    print(f\"âœ… MLflow ê¸°ë¡ ì™„ë£Œ!\")\n",
    "    print(f\"   Run ID: {mlflow.active_run().info.run_id}\")\n",
    "    print(f\"   ì‹¤í—˜: {experiment_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## âœ… ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### í•™ìŠµí•œ ë‚´ìš©\n",
    "- ONNX í¬ë§·ìœ¼ë¡œ ëª¨ë¸ ë³€í™˜\n",
    "- ë™ì  ì–‘ìí™” ì ìš©\n",
    "- ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬\n",
    "- MLflow ì‹¤í—˜ ì¶”ì \n",
    "\n",
    "### ë‹¤ìŒ ë‹¨ê³„\n",
    "- Lab 3-2 E2E Pipelineì— ëª¨ë¸ ìµœì í™” ì ìš©\n",
    "- KServeë¡œ ìµœì í™”ëœ ëª¨ë¸ ë°°í¬\n",
    "- Prometheus/Grafanaë¡œ ì¶”ë¡  ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
