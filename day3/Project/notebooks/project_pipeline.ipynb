{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ ì¡°ë³„ í”„ë¡œì íŠ¸: E2E MLOps Pipeline\n",
    "\n",
    "## ê°œìš”\n",
    "\n",
    "3ì¼ê°„ í•™ìŠµí•œ MLOps ê¸°ìˆ ì„ ì¢…í•©í•˜ì—¬ **ì™„ì „í•œ E2E ML íŒŒì´í”„ë¼ì¸**ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.\n",
    "\n",
    "### í‰ê°€ ê¸°ì¤€\n",
    "\n",
    "| í•­ëª© | ë°°ì  | ê¸°ì¤€ |\n",
    "|------|------|------|\n",
    "| Kubeflow Pipeline | 40ì  | ìµœì†Œ 5ê°œ ì»´í¬ë„ŒíŠ¸, Succeeded ìƒíƒœ |\n",
    "| MLflow Tracking | 20ì  | ìµœì†Œ 2íšŒ Run, íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­ ê¸°ë¡ |\n",
    "| Feature Engineering | 10ì  | 1ê°œ ì´ìƒ íŒŒìƒ í”¼ì²˜ ìƒì„± |\n",
    "| KServe ë°°í¬ (ì„ íƒ) | 25ì  | InferenceService ìƒì„± ë° API í…ŒìŠ¤íŠ¸ |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì •"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install kfp>=2.0.0 mlflow>=2.9.0 scikit-learn pandas numpy -q\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import os\n",
    "from kfp import dsl\n",
    "from kfp.dsl import component, Input, Output, Dataset\n",
    "from kfp import compiler\n",
    "import kfp\n",
    "\n",
    "print(f\"KFP Version: {kfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ TODO: íŒ€ ì„¤ì •ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”!\n",
    "TEAM_NAME = \"team-XX\"                        # ì˜ˆ: team-01, team-02, ...\n",
    "USER_NAMESPACE = \"kubeflow-user-example-com\" # í˜„ì¬ Kubeflow í”„ë¡œí•„ ë„¤ì„ìŠ¤í˜ì´ìŠ¤\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\"\n",
    "\n",
    "print(f\"Team: {TEAM_NAME}\")\n",
    "print(f\"Namespace: {USER_NAMESPACE}\")\n",
    "print(f\"MLflow URI: {MLFLOW_TRACKING_URI}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. ì»´í¬ë„ŒíŠ¸ êµ¬í˜„\n",
    "\n",
    "### 2.1 ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"scikit-learn==1.3.2\"]\n",
    ")\n",
    "def load_data(data_source: str, output_data: Output[Dataset]):\n",
    "    \"\"\"California Housing ë°ì´í„°ì…‹ ë¡œë“œ\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.datasets import fetch_california_housing\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"  Step 1: Load Data\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    housing = fetch_california_housing(as_frame=True)\n",
    "    df = housing.frame\n",
    "    \n",
    "    print(f\"  Source: {data_source}\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    \n",
    "    df.to_csv(output_data.path, index=False)\n",
    "    print(f\"  âœ… Data saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"scikit-learn==1.3.2\", \"numpy==1.24.3\"]\n",
    ")\n",
    "def preprocess(\n",
    "    input_data: Input[Dataset],\n",
    "    X_train_out: Output[Dataset],\n",
    "    X_test_out: Output[Dataset],\n",
    "    y_train_out: Output[Dataset],\n",
    "    y_test_out: Output[Dataset],\n",
    "    test_size: float = 0.2\n",
    "):\n",
    "    \"\"\"ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
    "    import pandas as pd\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"  Step 2: Preprocess\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    df = pd.read_csv(input_data.path)\n",
    "    \n",
    "    X = df.drop(columns=['MedHouseVal'])\n",
    "    y = df['MedHouseVal']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=42\n",
    "    )\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    X_train_scaled.to_csv(X_train_out.path, index=False)\n",
    "    X_test_scaled.to_csv(X_test_out.path, index=False)\n",
    "    y_train.to_csv(y_train_out.path, index=False)\n",
    "    y_test.to_csv(y_test_out.path, index=False)\n",
    "    \n",
    "    print(f\"  Train: {len(X_train)}, Test: {len(X_test)}\")\n",
    "    print(f\"  âœ… Preprocessing completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ â­ (í‰ê°€ í•­ëª©)\n",
    "\n",
    "**TODO**: íŒ€ì—ì„œ ì°½ì˜ì ì¸ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”!\n",
    "\n",
    "#### í”¼ì²˜ ì•„ì´ë””ì–´\n",
    "\n",
    "```python\n",
    "# 1. ë°©ë‹¹ ì¹¨ì‹¤ ë¹„ìœ¨\n",
    "df['bedroom_ratio'] = df['AveBedrms'] / df['AveRooms']\n",
    "\n",
    "# 2. ê°€êµ¬ë‹¹ ì¸êµ¬\n",
    "df['people_per_household'] = df['Population'] / df['AveOccup']\n",
    "\n",
    "# 3. Bay Areaê¹Œì§€ ê±°ë¦¬\n",
    "df['dist_to_bay'] = np.sqrt((df['Latitude']-37.77)**2 + (df['Longitude']+122.42)**2)\n",
    "\n",
    "# 4. ì†Œë“ êµ¬ê°„\n",
    "df['income_category'] = pd.cut(df['MedInc'], bins=5, labels=[1,2,3,4,5])\n",
    "\n",
    "# 5. ë°€ì§‘ë„\n",
    "df['density'] = df['Population'] * df['AveOccup']\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"numpy==1.24.3\"]\n",
    ")\n",
    "def feature_engineering(\n",
    "    X_train_in: Input[Dataset],\n",
    "    X_test_in: Input[Dataset],\n",
    "    X_train_out: Output[Dataset],\n",
    "    X_test_out: Output[Dataset]\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
    "    \n",
    "    â­ TODO: íŒ€ì—ì„œ ì°½ì˜ì ì¸ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”!\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"  Step 3: Feature Engineering\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    X_train = pd.read_csv(X_train_in.path)\n",
    "    X_test = pd.read_csv(X_test_in.path)\n",
    "    \n",
    "    original_cols = list(X_train.columns)\n",
    "    \n",
    "    def add_features(df):\n",
    "        \"\"\"â­ TODO: ì—¬ê¸°ì— ìƒˆë¡œìš´ í”¼ì²˜ë¥¼ ì¶”ê°€í•˜ì„¸ìš”!\"\"\"\n",
    "        df = df.copy()\n",
    "        \n",
    "        # ì˜ˆì‹œ 1: ë°©ë‹¹ ì¹¨ì‹¤ ë¹„ìœ¨\n",
    "        df['bedroom_ratio'] = df['AveBedrms'] / (df['AveRooms'] + 1e-6)\n",
    "        \n",
    "        # ì˜ˆì‹œ 2: ê°€êµ¬ë‹¹ ì¸êµ¬\n",
    "        df['people_per_household'] = df['Population'] / (df['AveOccup'] + 1e-6)\n",
    "        \n",
    "        # TODO: ë” ë§ì€ í”¼ì²˜ ì¶”ê°€!\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    X_train_fe = add_features(X_train)\n",
    "    X_test_fe = add_features(X_test)\n",
    "    \n",
    "    new_cols = [c for c in X_train_fe.columns if c not in original_cols]\n",
    "    print(f\"  New features: {new_cols}\")\n",
    "    print(f\"  Total features: {len(X_train_fe.columns)}\")\n",
    "    \n",
    "    X_train_fe.to_csv(X_train_out.path, index=False)\n",
    "    X_test_fe.to_csv(X_test_out.path, index=False)\n",
    "    \n",
    "    print(f\"  âœ… Feature engineering completed\")\n",
    "    return len(new_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ëª¨ë¸ í•™ìŠµ (MLflow ì—°ë™)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9-slim\",\n",
    "    packages_to_install=[\"pandas==2.0.3\", \"scikit-learn==1.3.2\", \"mlflow==2.9.2\", \"numpy==1.24.3\"]\n",
    ")\n",
    "def train_model(\n",
    "    X_train: Input[Dataset],\n",
    "    X_test: Input[Dataset],\n",
    "    y_train: Input[Dataset],\n",
    "    y_test: Input[Dataset],\n",
    "    mlflow_tracking_uri: str,\n",
    "    experiment_name: str,\n",
    "    team_name: str,\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10\n",
    ") -> str:\n",
    "    \"\"\"ëª¨ë¸ í•™ìŠµ ë° MLflow ê¸°ë¡\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import mlflow\n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "    from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "    import os\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(f\"  Step 4: Train Model - {team_name}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    X_train_df = pd.read_csv(X_train.path)\n",
    "    X_test_df = pd.read_csv(X_test.path)\n",
    "    y_train_df = pd.read_csv(y_train.path)\n",
    "    y_test_df = pd.read_csv(y_test.path)\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run(run_name=f\"{team_name}-run\") as run:\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        mlflow.log_params({\"n_estimators\": n_estimators, \"max_depth\": max_depth})\n",
    "        mlflow.set_tag(\"team\", team_name)\n",
    "        \n",
    "        model = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "        model.fit(X_train_df, y_train_df.values.ravel())\n",
    "        \n",
    "        y_pred = model.predict(X_test_df)\n",
    "        r2 = r2_score(y_test_df, y_pred)\n",
    "        rmse = np.sqrt(mean_squared_error(y_test_df, y_pred))\n",
    "        mae = mean_absolute_error(y_test_df, y_pred)\n",
    "        \n",
    "        mlflow.log_metrics({\"r2\": r2, \"rmse\": rmse, \"mae\": mae})\n",
    "        \n",
    "        print(f\"  R2: {r2:.4f}, RMSE: {rmse:.4f}, MAE: {mae:.4f}\")\n",
    "        print(f\"  âœ… Run ID: {run_id}\")\n",
    "    \n",
    "    return run_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ëª¨ë¸ í‰ê°€ ë° ë°°í¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(base_image=\"python:3.9-slim\", packages_to_install=[\"mlflow==2.9.2\"])\n",
    "def evaluate_model(run_id: str, mlflow_tracking_uri: str, r2_threshold: float = 0.75) -> str:\n",
    "    \"\"\"ëª¨ë¸ í‰ê°€ ë° ë°°í¬ ê²°ì •\"\"\"\n",
    "    import mlflow\n",
    "    import os\n",
    "    \n",
    "    os.environ['MLFLOW_TRACKING_URI'] = mlflow_tracking_uri\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    run = client.get_run(run_id)\n",
    "    r2 = float(run.data.metrics.get(\"r2\", 0))\n",
    "    \n",
    "    decision = \"deploy\" if r2 >= r2_threshold else \"skip\"\n",
    "    print(f\"  R2: {r2:.4f}, Threshold: {r2_threshold}, Decision: {decision}\")\n",
    "    \n",
    "    return decision\n",
    "\n",
    "\n",
    "@component(base_image=\"python:3.9-slim\", packages_to_install=[\"kubernetes==28.1.0\"])\n",
    "def deploy_model(run_id: str, model_name: str, namespace: str):\n",
    "    \"\"\"KServe ë°°í¬ (namespaceëŠ” í˜„ì¬ í”„ë¡œí•„ê³¼ ë™ì¼í•´ì•¼ í•¨)\"\"\"\n",
    "    from kubernetes import client, config\n",
    "    from kubernetes.client.rest import ApiException\n",
    "    import time\n",
    "    \n",
    "    print(f\"  Deploying {model_name} to {namespace}\")\n",
    "    \n",
    "    try:\n",
    "        config.load_incluster_config()\n",
    "    except:\n",
    "        config.load_kube_config()\n",
    "    \n",
    "    api = client.CustomObjectsApi()\n",
    "    isvc = {\n",
    "        \"apiVersion\": \"serving.kserve.io/v1beta1\",\n",
    "        \"kind\": \"InferenceService\",\n",
    "        \"metadata\": {\"name\": model_name, \"namespace\": namespace},\n",
    "        \"spec\": {\"predictor\": {\"sklearn\": {\"storageUri\": f\"mlflow-artifacts:/{run_id}/model\"}}}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        api.delete_namespaced_custom_object(\"serving.kserve.io\", \"v1beta1\", namespace, \"inferenceservices\", model_name)\n",
    "        time.sleep(5)\n",
    "    except ApiException:\n",
    "        pass\n",
    "    \n",
    "    api.create_namespaced_custom_object(\"serving.kserve.io\", \"v1beta1\", namespace, \"inferenceservices\", isvc)\n",
    "    print(f\"  âœ… InferenceService created\")\n",
    "\n",
    "\n",
    "@component(base_image=\"python:3.9-slim\")\n",
    "def send_alert(run_id: str, team_name: str):\n",
    "    \"\"\"ì„±ëŠ¥ ë¯¸ë‹¬ ì•Œë¦¼\"\"\"\n",
    "    print(f\"  âš ï¸ Alert: {team_name} model did not meet threshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. íŒŒì´í”„ë¼ì¸ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dsl.pipeline(name=\"Team Project Pipeline\", description=\"E2E ML Pipeline\")\n",
    "def project_pipeline(\n",
    "    data_source: str = \"sklearn\",\n",
    "    team_name: str = \"team-XX\",\n",
    "    experiment_name: str = \"team-XX-experiment\",\n",
    "    model_name: str = \"team-XX-model\",\n",
    "    namespace: str = \"kubeflow-user-example-com\",\n",
    "    mlflow_tracking_uri: str = \"http://mlflow-server-service.mlflow-system.svc.cluster.local:5000\",\n",
    "    n_estimators: int = 100,\n",
    "    max_depth: int = 10,\n",
    "    r2_threshold: float = 0.75\n",
    "):\n",
    "    load_task = load_data(data_source=data_source)\n",
    "    \n",
    "    preprocess_task = preprocess(input_data=load_task.outputs[\"output_data\"])\n",
    "    \n",
    "    feature_task = feature_engineering(\n",
    "        X_train_in=preprocess_task.outputs[\"X_train_out\"],\n",
    "        X_test_in=preprocess_task.outputs[\"X_test_out\"]\n",
    "    )\n",
    "    \n",
    "    train_task = train_model(\n",
    "        X_train=feature_task.outputs[\"X_train_out\"],\n",
    "        X_test=feature_task.outputs[\"X_test_out\"],\n",
    "        y_train=preprocess_task.outputs[\"y_train_out\"],\n",
    "        y_test=preprocess_task.outputs[\"y_test_out\"],\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        experiment_name=experiment_name,\n",
    "        team_name=team_name,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth\n",
    "    )\n",
    "    \n",
    "    evaluate_task = evaluate_model(\n",
    "        run_id=train_task.output,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        r2_threshold=r2_threshold\n",
    "    )\n",
    "    \n",
    "    with dsl.If(evaluate_task.output == \"deploy\"):\n",
    "        deploy_model(run_id=train_task.output, model_name=model_name, namespace=namespace)\n",
    "    \n",
    "    with dsl.If(evaluate_task.output == \"skip\"):\n",
    "        send_alert(run_id=train_task.output, team_name=team_name)\n",
    "\n",
    "print(\"âœ… íŒŒì´í”„ë¼ì¸ ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. ì»´íŒŒì¼ ë° ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì»´íŒŒì¼\n",
    "pipeline_file = f'{TEAM_NAME}_pipeline.yaml'\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=project_pipeline,\n",
    "    package_path=pipeline_file\n",
    ")\n",
    "\n",
    "print(f\"âœ… Pipeline compiled: {pipeline_file}\")\n",
    "print(f\"\")\n",
    "print(f\"ğŸ“‹ Next Steps:\")\n",
    "print(f\"  1. Kubeflow UI â†’ Pipelines â†’ Upload pipeline\")\n",
    "print(f\"  2. Select {pipeline_file}\")\n",
    "print(f\"  3. Create Run â†’ Set parameters\")\n",
    "print(f\"\")\n",
    "print(f\"âš ï¸  Important:\")\n",
    "print(f\"  namespace íŒŒë¼ë¯¸í„°ë¥¼ í˜„ì¬ Kubeflow í”„ë¡œí•„ê³¼ ë™ì¼í•˜ê²Œ ì„¤ì •í•˜ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\n",
    "\n",
    "### S3 ê¶Œí•œ ì˜¤ë¥˜\n",
    "```\n",
    "S3UploadFailedError: AccessDenied\n",
    "```\n",
    "â†’ ë³¸ ì½”ë“œëŠ” S3 artifact ì €ì¥ì„ ë¹„í™œì„±í™”í–ˆìœ¼ë¯€ë¡œ ë°œìƒí•˜ì§€ ì•ŠìŒ\n",
    "\n",
    "### RBAC ê¶Œí•œ ì˜¤ë¥˜\n",
    "```\n",
    "Forbidden: cannot create/delete inferenceservices\n",
    "```\n",
    "â†’ `namespace` íŒŒë¼ë¯¸í„°ë¥¼ í˜„ì¬ Kubeflow í”„ë¡œí•„ì˜ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •\n",
    "\n",
    "### ì»´í¬ë„ŒíŠ¸ ë°ì´í„° ì „ë‹¬ ì˜¤ë¥˜\n",
    "```python\n",
    "# âŒ ì˜ëª»ëœ ë°©ë²•\n",
    "train_task = train_model(X_train=preprocess_task)\n",
    "\n",
    "# âœ… ì˜¬ë°”ë¥¸ ë°©ë²•\n",
    "train_task = train_model(X_train=preprocess_task.outputs[\"X_train_out\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. ë°œí‘œ ì²´í¬ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "### í•„ìˆ˜ í™•ì¸ ì‚¬í•­\n",
    "- [ ] íŒŒì´í”„ë¼ì¸ ì»´íŒŒì¼ ì„±ê³µ\n",
    "- [ ] ëª¨ë“  ì»´í¬ë„ŒíŠ¸ Succeeded\n",
    "- [ ] MLflowì— Run ê¸°ë¡ í™•ì¸\n",
    "- [ ] Feature Engineeringì—ì„œ ìƒˆ í”¼ì²˜ ì¶”ê°€\n",
    "\n",
    "### ë°œí‘œ ë‚´ìš© (15ë¶„)\n",
    "1. íŒ€ ì†Œê°œ (1ë¶„)\n",
    "2. ì•„í‚¤í…ì²˜ (2ë¶„)\n",
    "3. êµ¬í˜„ í•˜ì´ë¼ì´íŠ¸ (4ë¶„) - Feature Engineering ì¤‘ì‹¬\n",
    "4. ë°ëª¨ (4ë¶„) - Kubeflow UI, MLflow UI\n",
    "5. íŠ¸ëŸ¬ë¸”ìŠˆíŒ… (1ë¶„)\n",
    "6. Q&A (3ë¶„)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
