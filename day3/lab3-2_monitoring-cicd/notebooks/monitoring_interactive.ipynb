{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 3-2: ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ ëŒ€í™”í˜• ì‹¤ìŠµ\n",
    "\n",
    "Jupyter Notebookì„ í†µí•´ Prometheus ë©”íŠ¸ë¦­ê³¼ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ëŒ€í™”í˜•ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ğŸ“‹ ì‹¤ìŠµ ë‚´ìš©\n",
    "\n",
    "1. í™˜ê²½ ì„¤ì • ë° Prometheus ì—°ê²°\n",
    "2. Prometheus ë©”íŠ¸ë¦­ íƒ€ì… (Counter, Gauge, Histogram, Summary)\n",
    "3. Custom Metrics ìƒì„± (ì¤‘ë³µ ë°©ì§€)\n",
    "4. PromQL ì¿¼ë¦¬ ì‹¤ìŠµ\n",
    "5. ë©”íŠ¸ë¦­ ì‹œê°í™”\n",
    "6. A/B í…ŒìŠ¤íŠ¸ ì‹œë®¬ë ˆì´ì…˜\n",
    "7. ì•Œë¦¼ ê·œì¹™ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "## ğŸ¢ í™˜ê²½\n",
    "\n",
    "- **Kubeflow Jupyter Notebook** (Kubernetes í´ëŸ¬ìŠ¤í„° ë‚´ë¶€)\n",
    "- **Prometheus**: `http://prometheus.monitoring.svc.cluster.local:9090`\n",
    "- **Namespace**: `monitoring`\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° íŒ¨í‚¤ì§€ ì„¤ì¹˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install prometheus-client requests pandas numpy matplotlib seaborn -q\n",
    "\n",
    "print(\"âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import requests\n",
    "from prometheus_client import REGISTRY, Counter, Gauge, Histogram, Summary, start_http_server\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plot ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"âœ… Import ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prometheus ì—°ê²° ì„¤ì • (ìë™ í™˜ê²½ ê°ì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Prometheus ì—°ê²° ì„¤ì • - í™˜ê²½ ìë™ ê°ì§€\n",
    "# ============================================================\n",
    "\n",
    "# í™˜ê²½ ê°ì§€\n",
    "is_kubernetes = os.path.exists('/var/run/secrets/kubernetes.io')\n",
    "\n",
    "# Prometheus URL ì„¤ì •\n",
    "if is_kubernetes:\n",
    "    # Kubeflow Notebook: Kubernetes Service DNS ì‚¬ìš©\n",
    "    PROMETHEUS_URL = os.getenv(\n",
    "        'PROMETHEUS_URL',\n",
    "        'http://prometheus.monitoring.svc.cluster.local:9090'\n",
    "    )\n",
    "    ENV = \"Kubeflow Notebook (Kubernetes í´ëŸ¬ìŠ¤í„° ë‚´ë¶€)\"\n",
    "else:\n",
    "    # ë¡œì»¬: Port-forward ì‚¬ìš©\n",
    "    PROMETHEUS_URL = os.getenv('PROMETHEUS_URL', 'http://localhost:9090')\n",
    "    ENV = \"ë¡œì»¬ ê°œë°œ í™˜ê²½ (Port-forward í•„ìš”)\"\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"Prometheus ì—°ê²° ì„¤ì •\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ¢ í™˜ê²½: {ENV}\")\n",
    "print(f\"ğŸ“¡ Prometheus URL: {PROMETHEUS_URL}\")\n",
    "print(f\"ğŸ“ Namespace: monitoring\")\n",
    "print(f\"ğŸ”Œ Service: prometheus\")\n",
    "print(f\"ğŸ”¢ Port: 9090\")\n",
    "\n",
    "# Prometheus ì¿¼ë¦¬ í•¨ìˆ˜\n",
    "def query_prometheus(query, timeout=10):\n",
    "    \"\"\"Prometheus ì¿¼ë¦¬ ì‹¤í–‰\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            f\"{PROMETHEUS_URL}/api/v1/query\",\n",
    "            params={'query': query},\n",
    "            timeout=timeout\n",
    "        )\n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {'error': f'HTTP {response.status_code}: {response.text}'}\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        return {\n",
    "            'error': 'Connection failed',\n",
    "            'hint': 'Prometheus ì„œë¹„ìŠ¤ê°€ monitoring namespaceì— ë°°í¬ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”'\n",
    "        }\n",
    "    except requests.exceptions.Timeout:\n",
    "        return {\n",
    "            'error': 'Request timeout',\n",
    "            'hint': 'Prometheus ì„œë¹„ìŠ¤ê°€ ì‘ë‹µí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤'\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {'error': str(e)}\n",
    "\n",
    "# ì—°ê²° í…ŒìŠ¤íŠ¸\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\" \" * 25 + \"ì—°ê²° í…ŒìŠ¤íŠ¸\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    response = requests.get(\n",
    "        f\"{PROMETHEUS_URL}/api/v1/query\",\n",
    "        params={'query': 'up'},\n",
    "        timeout=5\n",
    "    )\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"\\nâœ… Prometheus ì—°ê²° ì„±ê³µ!\")\n",
    "        \n",
    "        data = response.json()\n",
    "        if data.get('status') == 'success':\n",
    "            results = data.get('data', {}).get('result', [])\n",
    "            print(f\"âœ… {len(results)}ê°œ íƒ€ê²Ÿ ë°œê²¬\\n\")\n",
    "            \n",
    "            # íƒ€ê²Ÿ ì •ë³´ ì¶œë ¥\n",
    "            print(\"íƒ€ê²Ÿ ëª©ë¡:\")\n",
    "            for i, result in enumerate(results[:10], 1):\n",
    "                metric = result.get('metric', {})\n",
    "                value = result.get('value', [None, 'N/A'])[1]\n",
    "                job = metric.get('job', 'unknown')\n",
    "                instance = metric.get('instance', 'unknown')\n",
    "                status = \"ğŸŸ¢ UP\" if value == '1' else \"ğŸ”´ DOWN\"\n",
    "                print(f\"   {i}. [{status}] {job:20s} @ {instance}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 70)\n",
    "        print(\"âœ… ì„¤ì • ì™„ë£Œ! ì´ì œ ë©”íŠ¸ë¦­ ì‹¤ìŠµì„ ì‹œì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\nâŒ ì—°ê²° ì‹¤íŒ¨: HTTP {response.status_code}\")\n",
    "        print(f\"   Response: {response.text[:200]}\")\n",
    "        if not is_kubernetes:\n",
    "            print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "            print(\"   ìƒˆ í„°ë¯¸ë„ì—ì„œ ì‹¤í–‰: kubectl port-forward -n monitoring svc/prometheus 9090:9090\")\n",
    "        \nexcept requests.exceptions.ConnectionError as e:\n",
    "    print(f\"\\nâŒ ì—°ê²° ì‹¤íŒ¨: {e}\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    if is_kubernetes:\n",
    "        print(\"   kubectl get svc -n monitoring\")\n",
    "        print(\"   kubectl get pods -n monitoring\")\n",
    "    else:\n",
    "        print(\"   kubectl port-forward -n monitoring svc/prometheus 9090:9090\")\n",
    "        \nexcept Exception as e:\n",
    "    print(f\"\\nâŒ ì—ëŸ¬: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prometheus ë©”íŠ¸ë¦­ ìƒì„± (ì¤‘ë³µ ë°©ì§€)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ë©”íŠ¸ë¦­ í—¬í¼ í•¨ìˆ˜ - ì¤‘ë³µ ë°©ì§€\n",
    "# ============================================================\n",
    "\n",
    "def get_or_create_metric(metric_class, name, documentation, labelnames, **kwargs):\n",
    "    \"\"\"\n",
    "    ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„± (ì¤‘ë³µ ë°©ì§€)\n",
    "    \n",
    "    ì´ í•¨ìˆ˜ëŠ” Jupyter Notebookì—ì„œ ì…€ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„\n",
    "    'Duplicated timeseries' ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸\n",
    "    for collector in list(REGISTRY._collector_to_names.keys()):\n",
    "        if hasattr(collector, '_name') and collector._name == name:\n",
    "            return collector\n",
    "    \n",
    "    # ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±\n",
    "    try:\n",
    "        if kwargs:\n",
    "            return metric_class(name, documentation, labelnames, **kwargs)\n",
    "        else:\n",
    "            return metric_class(name, documentation, labelnames)\n",
    "    except ValueError as e:\n",
    "        # ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì¶©ëŒ ë°œìƒ ì‹œ ì œê±° í›„ ì¬ìƒì„±\n",
    "        if name in REGISTRY._names_to_collectors:\n",
    "            try:\n",
    "                REGISTRY.unregister(REGISTRY._names_to_collectors[name])\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if kwargs:\n",
    "            return metric_class(name, documentation, labelnames, **kwargs)\n",
    "        else:\n",
    "            return metric_class(name, documentation, labelnames)\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"âœ… ë©”íŠ¸ë¦­ í—¬í¼ í•¨ìˆ˜ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nì´ì œ Jupyter ì…€ì„ ì—¬ëŸ¬ ë²ˆ ì‹¤í–‰í•´ë„ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤!\")\n",
    "print(\"\\nì‚¬ìš© ì˜ˆ:\")\n",
    "print(\"  counter = get_or_create_metric(Counter, 'name', 'doc', ['labels'])\")\n",
    "print(\"  gauge = get_or_create_metric(Gauge, 'name', 'doc', ['labels'])\")\n",
    "print(\"  histogram = get_or_create_metric(Histogram, 'name', 'doc', ['labels'], buckets=(...))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Counter (ì¹´ìš´í„°) ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counter ìƒì„± (ì¤‘ë³µ ë°©ì§€)\n",
    "prediction_counter = get_or_create_metric(\n",
    "    Counter,\n",
    "    'model_predictions_total',\n",
    "    'Total number of predictions',\n",
    "    ['model_version', 'status']\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 25 + \"Counter ì‹¤ìŠµ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nCounter: ë‹¨ì¡° ì¦ê°€í•˜ëŠ” ê°’ (0ì—ì„œ ì‹œì‘, ì¦ê°€ë§Œ ê°€ëŠ¥)\")\n",
    "print(\"ì˜ˆ: ìš”ì²­ ìˆ˜, ì—ëŸ¬ ìˆ˜, ì™„ë£Œëœ ì‘ì—… ìˆ˜\\n\")\n",
    "\n",
    "# Counter ì¦ê°€\n",
    "print(\"10ê°œ ì˜ˆì¸¡ ì‹œë®¬ë ˆì´ì…˜...\")\n",
    "for i in range(10):\n",
    "    if random.random() > 0.1:  # 90% ì„±ê³µ\n",
    "        prediction_counter.labels(model_version='v1.0', status='success').inc()\n",
    "        print(f\"  {i+1}. âœ… ì˜ˆì¸¡ ì„±ê³µ\")\n",
    "    else:  # 10% ì‹¤íŒ¨\n",
    "        prediction_counter.labels(model_version='v1.0', status='error').inc()\n",
    "        print(f\"  {i+1}. âŒ ì˜ˆì¸¡ ì‹¤íŒ¨\")\n",
    "    time.sleep(0.1)\n",
    "\n",
    "print(\"\\nâœ… Counter ì¦ê°€ ì™„ë£Œ!\")\n",
    "print(\"ğŸ’¡ í˜„ì¬ ê°’ì€ ë‹¤ìŒ ì…€ì˜ HTTP Serverë¥¼ ì‹œì‘í•œ í›„ /metricsì—ì„œ í™•ì¸ ê°€ëŠ¥í•©ë‹ˆë‹¤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Gauge (ê²Œì´ì§€) ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gauge ìƒì„± (ì¤‘ë³µ ë°©ì§€)\n",
    "mae_gauge = get_or_create_metric(\n",
    "    Gauge,\n",
    "    'model_mae_score',\n",
    "    'Current MAE score of the model',\n",
    "    ['model_version']\n",
    ")\n",
    "\n",
    "r2_gauge = get_or_create_metric(\n",
    "    Gauge,\n",
    "    'model_r2_score',\n",
    "    'Current RÂ² score of the model',\n",
    "    ['model_version']\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"Gauge ì‹¤ìŠµ - ëª¨ë¸ ì„±ëŠ¥ ë©”íŠ¸ë¦­\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nGauge: ì¦ê°€/ê°ì†Œ ëª¨ë‘ ê°€ëŠ¥í•œ ê°’\")\n",
    "print(\"ì˜ˆ: CPU ì‚¬ìš©ë¥ , ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ëª¨ë¸ ì„±ëŠ¥ ì ìˆ˜\\n\")\n",
    "\n",
    "# Gauge ê°’ ì‹œë®¬ë ˆì´ì…˜\n",
    "mae_values = []\n",
    "r2_values = []\n",
    "\n",
    "print(\"20ìŠ¤í… ë™ì•ˆ ëª¨ë¸ ì„±ëŠ¥ ë³€í™” ì‹œë®¬ë ˆì´ì…˜...\\n\")\n",
    "for i in range(20):\n",
    "    # v1.0 ëª¨ë¸ - ì•ˆì •ì \n",
    "    mae_v1 = 0.445 + random.gauss(0, 0.01)\n",
    "    r2_v1 = 0.798 + random.gauss(0, 0.005)\n",
    "    \n",
    "    # v2.0 ëª¨ë¸ - ë” ì¢‹ì€ ì„±ëŠ¥\n",
    "    mae_v2 = 0.362 + random.gauss(0, 0.01)\n",
    "    r2_v2 = 0.885 + random.gauss(0, 0.005)\n",
    "    \n",
    "    # Gauge ì—…ë°ì´íŠ¸\n",
    "    mae_gauge.labels(model_version='v1.0').set(mae_v1)\n",
    "    r2_gauge.labels(model_version='v1.0').set(r2_v1)\n",
    "    mae_gauge.labels(model_version='v2.0').set(mae_v2)\n",
    "    r2_gauge.labels(model_version='v2.0').set(r2_v2)\n",
    "    \n",
    "    mae_values.append({'v1.0': mae_v1, 'v2.0': mae_v2})\n",
    "    r2_values.append({'v1.0': r2_v1, 'v2.0': r2_v2})\n",
    "    \n",
    "    if (i + 1) % 5 == 0:\n",
    "        print(f\"Step {i+1:2d} | v1.0: MAE={mae_v1:.4f}, RÂ²={r2_v1:.4f} | v2.0: MAE={mae_v2:.4f}, RÂ²={r2_v2:.4f}\")\n",
    "    \n",
    "    time.sleep(0.05)\n",
    "\n",
    "print(\"\\nâœ… Gauge ì—…ë°ì´íŠ¸ ì™„ë£Œ!\")\n",
    "print(f\"\\nğŸ“Š í‰ê·  ì„±ëŠ¥:\")\n",
    "print(f\"   v1.0: MAE={np.mean([v['v1.0'] for v in mae_values]):.4f}, RÂ²={np.mean([v['v1.0'] for v in r2_values]):.4f}\")\n",
    "print(f\"   v2.0: MAE={np.mean([v['v2.0'] for v in mae_values]):.4f}, RÂ²={np.mean([v['v2.0'] for v in r2_values]):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Histogram (íˆìŠ¤í† ê·¸ë¨) ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram ìƒì„± (ì¤‘ë³µ ë°©ì§€)\n",
    "latency_histogram = get_or_create_metric(\n",
    "    Histogram,\n",
    "    'model_prediction_latency_seconds',\n",
    "    'Prediction latency in seconds',\n",
    "    ['model_version'],\n",
    "    buckets=(0.01, 0.025, 0.05, 0.075, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0)\n",
    ")\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"Histogram ì‹¤ìŠµ - ì˜ˆì¸¡ ë ˆì´í„´ì‹œ\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nHistogram: ê°’ì˜ ë¶„í¬ë¥¼ ì¸¡ì • (ë²„í‚·ë³„ ë¹ˆë„)\")\n",
    "print(\"ì˜ˆ: ì‘ë‹µ ì‹œê°„, ìš”ì²­ í¬ê¸°\\n\")\n",
    "\n",
    "# Latency ì‹œë®¬ë ˆì´ì…˜\n",
    "latencies_v1 = []\n",
    "latencies_v2 = []\n",
    "\n",
    "print(\"100ê°œ ì˜ˆì¸¡ì˜ ë ˆì´í„´ì‹œ ì¸¡ì •...\")\n",
    "for i in range(100):\n",
    "    # v1.0: í‰ê·  50ms, ë” í° ë³€ë™\n",
    "    latency_v1 = abs(random.gauss(0.05, 0.02))\n",
    "    latency_histogram.labels(model_version='v1.0').observe(latency_v1)\n",
    "    latencies_v1.append(latency_v1)\n",
    "    \n",
    "    # v2.0: í‰ê·  40ms, ë” ì•ˆì •ì \n",
    "    latency_v2 = abs(random.gauss(0.04, 0.01))\n",
    "    latency_histogram.labels(model_version='v2.0').observe(latency_v2)\n",
    "    latencies_v2.append(latency_v2)\n",
    "\n",
    "print(f\"\\nâœ… Histogram ê´€ì¸¡ ì™„ë£Œ!\")\n",
    "print(f\"\\nğŸ“Š v1.0 ë ˆì´í„´ì‹œ: í‰ê·  {np.mean(latencies_v1)*1000:.2f}ms, p95 {np.percentile(latencies_v1, 95)*1000:.2f}ms, p99 {np.percentile(latencies_v1, 99)*1000:.2f}ms\")\n",
    "print(f\"ğŸ“Š v2.0 ë ˆì´í„´ì‹œ: í‰ê·  {np.mean(latencies_v2)*1000:.2f}ms, p95 {np.percentile(latencies_v2, 95)*1000:.2f}ms, p99 {np.percentile(latencies_v2, 99)*1000:.2f}ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Prometheus HTTP Server ì‹œì‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prometheus HTTP Server ì‹œì‘\n",
    "PORT = 8000\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 20 + \"Prometheus Metrics Server\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    start_http_server(PORT)\n",
    "    print(f\"\\nâœ… Metrics Server ì‹œì‘ ì„±ê³µ!\")\n",
    "    print(f\"\\nğŸ“¡ Metrics Endpoint: http://localhost:{PORT}/metrics\")\n",
    "    print(f\"\\nìƒˆ í„°ë¯¸ë„ì—ì„œ í™•ì¸:\")\n",
    "    print(f\"  curl http://localhost:{PORT}/metrics | grep model\")\n",
    "    print(f\"\\në˜ëŠ” ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†í•˜ì„¸ìš”!\")\n",
    "except OSError as e:\n",
    "    print(f\"\\nâš ï¸  í¬íŠ¸ {PORT}ì´(ê°€) ì´ë¯¸ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤\")\n",
    "    print(\"   Metrics serverê°€ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\")\n",
    "    print(f\"   ê³„ì† ì§„í–‰ ê°€ëŠ¥: http://localhost:{PORT}/metrics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. ë©”íŠ¸ë¦­ ì‹œê°í™”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAE & RÂ² ì‹œê°í™”\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# MAE ë¹„êµ\n",
    "mae_df = pd.DataFrame(mae_values)\n",
    "mae_df.plot(ax=ax1, title='Model MAE Over Time', ylabel='MAE', xlabel='Step', linewidth=2)\n",
    "ax1.legend(['v1.0', 'v2.0'], loc='best')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RÂ² ë¹„êµ\n",
    "r2_df = pd.DataFrame(r2_values)\n",
    "r2_df.plot(ax=ax2, title='Model RÂ² Score Over Time', ylabel='RÂ² Score', xlabel='Step', linewidth=2)\n",
    "ax2.legend(['v1.0', 'v2.0'], loc='best')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "mae_improvement = (1 - mae_df['v2.0'].mean() / mae_df['v1.0'].mean()) * 100\n",
    "print(f\"   v1.0: MAE={mae_df['v1.0'].mean():.4f}, RÂ²={r2_df['v1.0'].mean():.4f}\")\n",
    "print(f\"   v2.0: MAE={mae_df['v2.0'].mean():.4f}, RÂ²={r2_df['v2.0'].mean():.4f}\")\n",
    "print(f\"\\nâœ¨ v2.0ì´ MAE {mae_improvement:.1f}% ê°œì„ !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latency ë¶„í¬ ì‹œê°í™”\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(np.array(latencies_v1)*1000, bins=30, alpha=0.7, label='v1.0', color='blue')\n",
    "ax1.hist(np.array(latencies_v2)*1000, bins=30, alpha=0.7, label='v2.0', color='orange')\n",
    "ax1.set_xlabel('Latency (ms)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Prediction Latency Distribution')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "latency_df = pd.DataFrame({\n",
    "    'v1.0': np.array(latencies_v1)*1000,\n",
    "    'v2.0': np.array(latencies_v2)*1000\n",
    "})\n",
    "latency_df.boxplot(ax=ax2)\n",
    "ax2.set_ylabel('Latency (ms)')\n",
    "ax2.set_title('Latency Comparison')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. PromQL ì¿¼ë¦¬ ì‹¤ìŠµ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PromQL ì¿¼ë¦¬ ì˜ˆì œ\n",
    "queries = [\n",
    "    (\"í˜„ì¬ MAE ê°’\", 'model_mae_score'),\n",
    "    (\"í˜„ì¬ RÂ² ê°’\", 'model_r2_score'),\n",
    "    (\"ì´ ì˜ˆì¸¡ ìˆ˜\", 'model_predictions_total'),\n",
    "    (\"ìµœê·¼ 5ë¶„ ì˜ˆì¸¡ ì¦ê°€ìœ¨\", 'rate(model_predictions_total[5m])'),\n",
    "    (\"p95 ë ˆì´í„´ì‹œ\", 'histogram_quantile(0.95, rate(model_prediction_latency_seconds_bucket[5m]))'),\n",
    "]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\" \" * 25 + \"PromQL ì¿¼ë¦¬ ì˜ˆì œ\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Prometheus ì—°ê²° í™•ì¸\n",
    "connection_ok = False\n",
    "try:\n",
    "    test = requests.get(f\"{PROMETHEUS_URL}/api/v1/query\", params={'query': 'up'}, timeout=2)\n",
    "    connection_ok = (test.status_code == 200)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "if not connection_ok:\n",
    "    print(\"\\nâš ï¸  Prometheusì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"   í˜„ì¬ URL: {PROMETHEUS_URL}\")\n",
    "    print(\"\\nğŸ’¡ í•´ê²° ë°©ë²•:\")\n",
    "    if not is_kubernetes:\n",
    "        print(\"   kubectl port-forward -n monitoring svc/prometheus 9090:9090\")\n",
    "    else:\n",
    "        print(\"   kubectl get svc -n monitoring\")\n",
    "        print(\"   kubectl get pods -n monitoring\")\n",
    "else:\n",
    "    print(\"\\nâœ… Prometheus ì—°ê²° í™•ì¸ë¨\\n\")\n",
    "    \n",
    "    for description, query in queries:\n",
    "        print(f\"{'='*70}\")\n",
    "        print(f\"ğŸ“Š {description}\")\n",
    "        print(f\"   Query: {query}\")\n",
    "        \n",
    "        result = query_prometheus(query)\n",
    "        \n",
    "        if 'error' in result:\n",
    "            print(f\"   âš ï¸  Error: {result['error']}\")\n",
    "            if 'hint' in result:\n",
    "                print(f\"   ğŸ’¡ Hint: {result['hint']}\")\n",
    "        elif result.get('status') == 'success':\n",
    "            data = result.get('data', {}).get('result', [])\n",
    "            if data:\n",
    "                for item in data[:3]:\n",
    "                    labels = item.get('metric', {})\n",
    "                    value = item.get('value', [None, 'N/A'])[1]\n",
    "                    label_str = ', '.join([f\"{k}={v}\" for k, v in labels.items()]) if labels else 'no labels'\n",
    "                    print(f\"   âœ… [{label_str}] = {value}\")\n",
    "            else:\n",
    "                print(\"   â„¹ï¸  No data (ë©”íŠ¸ë¦­ì´ Prometheusì— ìˆ˜ì§‘ë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤)\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. ì‹¤ìŠµ ì™„ë£Œ!\n",
    "\n",
    "### âœ… í•™ìŠµí•œ ë‚´ìš©\n",
    "\n",
    "- Prometheus ì—°ê²° ì„¤ì • (í™˜ê²½ ìë™ ê°ì§€)\n",
    "- ë©”íŠ¸ë¦­ ì¤‘ë³µ ë°©ì§€ (Jupyter ì¬ì‹¤í–‰ ê°€ëŠ¥)\n",
    "- Prometheus ë©”íŠ¸ë¦­ íƒ€ì… (Counter, Gauge, Histogram)\n",
    "- PromQL ì¿¼ë¦¬ ì‘ì„± ë° ì‹¤í–‰\n",
    "- ë©”íŠ¸ë¦­ ì‹œê°í™” (Matplotlib)\n",
    "\n",
    "### ğŸ“š ë‹¤ìŒ ë‹¨ê³„\n",
    "\n",
    "1. **Grafana ëŒ€ì‹œë³´ë“œ** - ë©”íŠ¸ë¦­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì‹œê°í™”\n",
    "2. **Alertmanager ì„¤ì •** - ì•Œë¦¼ ê·œì¹™ êµ¬ì„± ë° Slack ì—°ë™\n",
    "3. **í”„ë¡œë•ì…˜ ë°°í¬** - Kubernetesì— ì „ì²´ ëª¨ë‹ˆí„°ë§ ìŠ¤íƒ ë°°í¬\n",
    "\n",
    "---\n",
    "\n",
    "Â© 2024 í˜„ëŒ€ì˜¤í† ì—ë²„ MLOps Training - Lab 3-2  \n",
    "**Environment**: Kubeflow Jupyter Notebook  \n",
    "**Prometheus**: http://prometheus.monitoring.svc.cluster.local:9090"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
