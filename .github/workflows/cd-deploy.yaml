name: CD - Deploy Model

on:
  workflow_run:
    workflows: ["CI - Test Model"]
    types: [ completed ]
    branches: [ main ]

jobs:
  deploy:
    name: Build and Deploy Model
    runs-on: ubuntu-latest
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: Set image tag
        id: image-tag
        run: |
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          echo "tag=v$(date +%Y%m%d)-${SHORT_SHA}" >> $GITHUB_OUTPUT
          echo "timestamp=$(date +%Y%m%d-%H%M%S)" >> $GITHUB_OUTPUT

      - name: Check if Dockerfile exists
        id: check-dockerfile
        run: |
          if [ -f "Dockerfile" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Dockerfile found in repository"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  Dockerfile not found - will generate automatically"
          fi
      
      - name: Generate Dockerfile (if not exists)
        if: steps.check-dockerfile.outputs.exists == 'false'
        run: |
          echo "üìù Generating application files for California Housing model..."
          
          # Create api.py
          cat > api.py << 'APIEOF'
          from fastapi import FastAPI, HTTPException
          from pydantic import BaseModel, Field
          from typing import List
          import numpy as np
          from sklearn.datasets import fetch_california_housing
          from sklearn.ensemble import RandomForestRegressor
          from sklearn.model_selection import train_test_split
          import logging
          import os
          
          logging.basicConfig(level=logging.INFO)
          logger = logging.getLogger(__name__)
          
          app = FastAPI(
              title="California Housing Model API",
              description="ML model for California Housing price predictions",
              version=os.getenv("MODEL_VERSION", "v1.0")
          )
          
          model = None
          feature_names = None
          
          class PredictionRequest(BaseModel):
              features: List[float] = Field(..., description="8 features for California Housing")
          
          class PredictionResponse(BaseModel):
              prediction: float
              model_version: str
              features_used: List[str]
          
          @app.on_event("startup")
          async def load_model():
              global model, feature_names
              logger.info("Loading California Housing dataset...")
              housing = fetch_california_housing()
              X, y = housing.data, housing.target
              feature_names = housing.feature_names
              
              logger.info("Training Random Forest model...")
              X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
              model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
              model.fit(X_train, y_train)
              
              score = model.score(X_test, y_test)
              logger.info(f"Model trained! R¬≤ score: {score:.4f}")
          
          @app.get("/")
          async def root():
              return {"message": "California Housing Model API", "version": os.getenv("MODEL_VERSION", "v1.0")}
          
          @app.get("/health")
          async def health():
              return {"status": "healthy" if model else "unhealthy", "model_loaded": model is not None}
          
          @app.post("/predict", response_model=PredictionResponse)
          async def predict(request: PredictionRequest):
              if model is None:
                  raise HTTPException(status_code=503, detail="Model not loaded")
              if len(request.features) != 8:
                  raise HTTPException(status_code=400, detail=f"Expected 8 features, got {len(request.features)}")
              
              features_array = np.array(request.features).reshape(1, -1)
              prediction = model.predict(features_array)[0]
              
              return PredictionResponse(
                  prediction=float(prediction),
                  model_version=os.getenv("MODEL_VERSION", "v1.0"),
                  features_used=list(feature_names)
              )
          
          @app.get("/metrics")
          async def metrics():
              return {"model_loaded": model is not None, "model_version": os.getenv("MODEL_VERSION", "v1.0")}
          APIEOF
          
          # Create Dockerfile
          cat > Dockerfile << 'DOCKEREOF'
          # California Housing Model Serving Dockerfile
          # Auto-generated by GitHub Actions CD pipeline
          
          FROM python:3.9-slim
          
          ARG MODEL_VERSION=latest
          ARG BUILD_DATE
          ARG VCS_REF
          
          LABEL maintainer="MLOps Team" \
                version="${MODEL_VERSION}" \
                description="California Housing Model API" \
                build-date="${BUILD_DATE}" \
                vcs-ref="${VCS_REF}"
          
          WORKDIR /app
          
          RUN apt-get update && apt-get install -y curl && rm -rf /var/lib/apt/lists/*
          
          COPY requirements.txt .
          RUN pip install --no-cache-dir -r requirements.txt && \
              pip install --no-cache-dir fastapi==0.104.1 uvicorn[standard]==0.24.0 pydantic==2.5.0
          
          COPY api.py .
          
          EXPOSE 8000
          
          ENV MODEL_VERSION=${MODEL_VERSION} \
              PYTHONUNBUFFERED=1
          
          HEALTHCHECK --interval=30s --timeout=3s --start-period=10s --retries=3 \
              CMD curl -f http://localhost:8000/health || exit 1
          
          CMD ["uvicorn", "api:app", "--host", "0.0.0.0", "--port", "8000"]
          DOCKEREOF
          
          echo "‚úÖ Application files generated successfully"
          echo ""
          echo "üìÑ Generated api.py ($(wc -l < api.py) lines)"
          echo "üìÑ Generated Dockerfile ($(wc -l < Dockerfile) lines)"

      - name: Build Docker image
        if: steps.check-dockerfile.outputs.exists == 'true' || steps.check-dockerfile.outputs.exists == 'false'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ml-model-california-housing
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "Building image: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"
          docker build \
            --platform linux/amd64 \
            --build-arg MODEL_VERSION=$IMAGE_TAG \
            --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \
            --build-arg VCS_REF=${{ github.sha }} \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG \
            -t $ECR_REGISTRY/$ECR_REPOSITORY:latest \
            -f Dockerfile .

      - name: Scan image for vulnerabilities
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ml-model-california-housing
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          # Install Trivy scanner
          wget -qO - https://aquasecurity.github.io/trivy-repo/deb/public.key | sudo apt-key add -
          echo "deb https://aquasecurity.github.io/trivy-repo/deb $(lsb_release -sc) main" | sudo tee -a /etc/apt/sources.list.d/trivy.list
          sudo apt-get update
          sudo apt-get install trivy
          
          # Scan image
          trivy image --severity HIGH,CRITICAL $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG

      - name: Push image to ECR
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ml-model-california-housing
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG
          docker push $ECR_REGISTRY/$ECR_REPOSITORY:latest
          echo "‚úÖ Image pushed: $ECR_REGISTRY/$ECR_REPOSITORY:$IMAGE_TAG"

      - name: Check Kubernetes configuration
        id: check-k8s
        run: |
          if [ -n "${{ secrets.KUBECONFIG_DATA }}" ]; then
            echo "configured=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Kubernetes configuration available"
          else
            echo "configured=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  KUBECONFIG_DATA not configured - skipping K8s deployment"
          fi

      - name: Set up kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        uses: azure/setup-kubectl@v3
        with:
          version: 'v1.28.0'
      
      - name: Install aws-iam-authenticator
        if: steps.check-k8s.outputs.configured == 'true'
        run: |
          echo "üì¶ Installing aws-iam-authenticator..."
          curl -Lo aws-iam-authenticator https://github.com/kubernetes-sigs/aws-iam-authenticator/releases/download/v0.6.14/aws-iam-authenticator_0.6.14_linux_amd64
          chmod +x aws-iam-authenticator
          sudo mv aws-iam-authenticator /usr/local/bin/
          aws-iam-authenticator version
          echo "‚úÖ aws-iam-authenticator installed"

      - name: Configure kubectl
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          KUBECONFIG_DATA: ${{ secrets.KUBECONFIG_DATA }}
        run: |
          mkdir -p ~/.kube
          echo "$KUBECONFIG_DATA" | base64 -d > ~/.kube/config
          chmod 600 ~/.kube/config
          echo "‚úÖ Kubeconfig configured"
          
          # Verify connection
          if kubectl cluster-info; then
            echo "‚úÖ Successfully connected to Kubernetes cluster"
          else
            echo "‚ö†Ô∏è  Failed to connect to Kubernetes cluster"
            exit 1
          fi

      - name: Update KServe InferenceService
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ml-model-california-housing
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          cat <<EOF | kubectl apply -f -
          apiVersion: serving.kserve.io/v1beta1
          kind: InferenceService
          metadata:
            name: california-housing-predictor
            namespace: ${NAMESPACE}
            annotations:
              serving.kserve.io/deploymentMode: RawDeployment
          spec:
            predictor:
              minReplicas: 1
              maxReplicas: 3
              containers:
                - name: kserve-container
                  image: ${ECR_REGISTRY}/${ECR_REPOSITORY}:${IMAGE_TAG}
                  ports:
                    - containerPort: 8000
                      protocol: TCP
                  env:
                    - name: MODEL_NAME
                      value: california-housing
                    - name: MODEL_VERSION
                      value: ${IMAGE_TAG}
                  resources:
                    requests:
                      cpu: 500m
                      memory: 1Gi
                    limits:
                      cpu: 1000m
                      memory: 2Gi
                  readinessProbe:
                    httpGet:
                      path: /health
                      port: 8000
                    initialDelaySeconds: 30
                    periodSeconds: 10
                    timeoutSeconds: 5
                    failureThreshold: 3
                  livenessProbe:
                    httpGet:
                      path: /health
                      port: 8000
                    initialDelaySeconds: 60
                    periodSeconds: 20
                    timeoutSeconds: 5
                    failureThreshold: 3
              canaryTrafficPercent: 10  # Start with 10% canary traffic
          EOF

      - name: Wait for deployment
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "Waiting for InferenceService to be ready..."
          echo "This may take up to 5 minutes for image pull and container startup"
          
          # Check initial status
          kubectl get inferenceservice california-housing-predictor -n ${NAMESPACE} || true
          
          # Wait with timeout
          if kubectl wait --for=condition=Ready \
            inferenceservice/california-housing-predictor \
            -n ${NAMESPACE} \
            --timeout=300s; then
            echo "‚úÖ InferenceService is ready!"
          else
            echo "‚ùå InferenceService failed to become ready"
            echo ""
            echo "=== InferenceService Status ==="
            kubectl get inferenceservice california-housing-predictor -n ${NAMESPACE} -o yaml || true
            echo ""
            echo "=== Pod Status ==="
            kubectl get pods -n ${NAMESPACE} -l serving.kserve.io/inferenceservice=california-housing-predictor || true
            echo ""
            echo "=== Pod Describe ==="
            kubectl describe pods -n ${NAMESPACE} -l serving.kserve.io/inferenceservice=california-housing-predictor || true
            echo ""
            echo "=== Pod Logs ==="
            POD_NAME=$(kubectl get pods -n ${NAMESPACE} -l serving.kserve.io/inferenceservice=california-housing-predictor -o jsonpath='{.items[0].metadata.name}' 2>/dev/null || echo "")
            if [ -n "$POD_NAME" ]; then
              kubectl logs -n ${NAMESPACE} $POD_NAME --all-containers=true --tail=100 || true
            fi
            echo ""
            echo "=== Events ==="
            kubectl get events -n ${NAMESPACE} --sort-by='.lastTimestamp' | tail -20 || true
            
            exit 1
          fi

      - name: Test deployed model
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          # Get service endpoint (use port-forward for testing)
          echo "Setting up port-forward for testing..."
          POD_NAME=$(kubectl get pods -n ${NAMESPACE} \
            -l serving.kserve.io/inferenceservice=california-housing-predictor \
            -o jsonpath='{.items[0].metadata.name}')
          
          echo "Pod: $POD_NAME"
          
          # Port-forward in background
          kubectl port-forward -n ${NAMESPACE} pod/$POD_NAME 8000:8000 &
          PF_PID=$!
          sleep 5
          
          # Test health endpoint
          echo "Testing /health endpoint..."
          if curl -f http://localhost:8000/health; then
            echo "‚úÖ Health check passed"
          else
            echo "‚ùå Health check failed"
            kill $PF_PID || true
            exit 1
          fi
          
          # Test predict endpoint
          echo ""
          echo "Testing /predict endpoint..."
          RESPONSE=$(curl -s -X POST http://localhost:8000/predict \
            -H "Content-Type: application/json" \
            -d '{
              "features": [8.3252, 41.0, 6.98, 1.02, 322.0, 2.55, 37.88, -122.23]
            }')
          
          echo "Response: $RESPONSE"
          
          # Check if prediction is present
          if echo "$RESPONSE" | grep -q "prediction"; then
            echo "‚úÖ Prediction endpoint working"
            PREDICTION=$(echo "$RESPONSE" | grep -o '"prediction":[^,}]*' | cut -d':' -f2)
            echo "üìä Predicted value: $PREDICTION"
          else
            echo "‚ùå Prediction endpoint failed"
            kill $PF_PID || true
            exit 1
          fi
          
          # Cleanup
          kill $PF_PID || true
          echo ""
          echo "‚úÖ Model deployment test successful!"

      - name: Update traffic split (gradual rollout)
        if: steps.check-k8s.outputs.configured == 'true'
        env:
          NAMESPACE: ${{ secrets.KSERVE_NAMESPACE || 'kubeflow-user01' }}
        run: |
          echo "‚úÖ Deployment successful!"
          echo "Canary deployment is live with 10% traffic"
          echo ""
          echo "Next steps for gradual rollout:"
          echo "  1. Monitor metrics in Grafana for 30 minutes"
          echo "  2. If stable, increase to 50%: kubectl patch inferenceservice ..."
          echo "  3. If stable, increase to 100%: kubectl patch inferenceservice ..."
      
      - name: Skip Kubernetes deployment notice
        if: steps.check-k8s.outputs.configured == 'false'
        run: |
          echo "‚ö†Ô∏è  Kubernetes deployment skipped (KUBECONFIG_DATA not configured)"
          echo ""
          echo "‚úÖ Successfully completed:"
          echo "  - Docker image built: ${ECR_REGISTRY}/${ECR_REPOSITORY}:${IMAGE_TAG}"
          echo "  - Image pushed to ECR"
          echo "  - Image scanned for vulnerabilities"
          echo ""
          echo "üìù To enable Kubernetes deployment:"
          echo "  1. Configure KUBECONFIG_DATA secret in GitHub repository"
          echo "  2. Ensure KServe is installed in your cluster"
          echo "  3. Set KSERVE_NAMESPACE secret (default: kubeflow-user01)"
          echo ""
          echo "üí° For Lab 3-2, the monitoring stack is the main focus."
          echo "   KServe deployment is an optional advanced feature."
        env:
          ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
          ECR_REPOSITORY: ml-model-california-housing
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}

      - name: Send Slack notification
        if: always()
        continue-on-error: true
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          if [ -z "$SLACK_WEBHOOK_URL" ]; then
            echo "‚ö†Ô∏è  SLACK_WEBHOOK_URL not configured - skipping notification"
            exit 0
          fi
          
          STATUS="${{ job.status }}"
          COLOR="good"
          if [ "$STATUS" != "success" ]; then
            COLOR="danger"
          fi
          
          curl -X POST $SLACK_WEBHOOK_URL \
            -H 'Content-Type: application/json' \
            -d '{
              "attachments": [{
                "color": "'$COLOR'",
                "title": "Model Deployment '$STATUS'",
                "fields": [
                  {
                    "title": "Repository",
                    "value": "'"${{ github.repository }}"'",
                    "short": true
                  },
                  {
                    "title": "Branch",
                    "value": "'"${{ github.ref_name }}"'",
                    "short": true
                  },
                  {
                    "title": "Image Tag",
                    "value": "'"$IMAGE_TAG"'",
                    "short": true
                  },
                  {
                    "title": "Commit",
                    "value": "<https://github.com/'"${{ github.repository }}"'/commit/'"${{ github.sha }}"'|'"${GITHUB_SHA:0:7}"'>",
                    "short": true
                  }
                ],
                "footer": "GitHub Actions",
                "footer_icon": "https://github.githubassets.com/favicon.ico",
                "ts": '"$(date +%s)"'
              }]
            }'

      - name: Generate deployment summary
        if: always()
        env:
          IMAGE_TAG: ${{ steps.image-tag.outputs.tag }}
        run: |
          echo "## Deployment Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Status:** ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "**Image Tag:** $IMAGE_TAG" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** ${{ github.sha }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Deployment Details" >> $GITHUB_STEP_SUMMARY
          echo "- Canary Traffic: 10%" >> $GITHUB_STEP_SUMMARY
          echo "- Min Replicas: 1" >> $GITHUB_STEP_SUMMARY
          echo "- Max Replicas: 3" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Monitoring" >> $GITHUB_STEP_SUMMARY
          echo "- [Grafana Dashboard](http://grafana.monitoring.svc.cluster.local:3000)" >> $GITHUB_STEP_SUMMARY
          echo "- [Prometheus](http://prometheus.monitoring.svc.cluster.local:9090)" >> $GITHUB_STEP_SUMMARY
